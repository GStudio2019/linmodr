---
title: "Линейные модели с дискретными предикторами"
subtitle: "Линейные модели..."
author: "Марина Варфоломеева, Вадим Хайтов"
output:
  beamer_presentation:
    colortheme: beaver
    highlight: tango
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - --latex-engine=xelatex
    - -V fontsize=10pt
    - -V lang=russian
    slide_level: 2
    theme: default
    toc: no
institute: "Кафедра Зоологии беспозвоночных, Биологический факультет, СПбГУ"
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
options(width = 70, scipen = 6)
library(knitr)
# chunk default options
opts_chunk$set(fig.show='hold', size='footnotesize', comment="#", warning=FALSE, message=FALSE, dev='cairo_pdf', fig.height=2.5, fig.width=7.7)
# library("extrafont")
source("support_linmodr.R")
```

## Линейные модели с дискретными предикторами (дисперсионный анализ)

### Вы сможете

- Объяснить, в чем опасность множественных сравнений, и как с ними можно бороться
- Рассказать, как в дисперсионном анализе моделируются значения зависимой переменной
- Интерпретировать и описать результаты, записанные в таблице дисперсионного анализа
- Перечислить и проверить условия применимости дисперсионного анализа
- Провести множественные попарные сравнения при помощи post hoc теста Тьюки, представить и описать их результаты
- Построить график результатов дисперсионного анализа


# Множественные сравнения

## Пример: яйца кукушек

- `species`  --- вид птиц-хозяев (фактор)
- `length` --- длина яиц кукушек в гнездах хозяев (зависимая переменная)

```{r, data-cu}
library(DAAG)
data("cuckoos")
# Положим данные в переменную с коротким названием, чтобы меньше печатать
cu <- cuckoos
head(cu, 3)
```

\vskip0pt plus 1filll
\tiny Данные: Latter, 1902; источник: Tippett, 1931

## Исследуем данные

```{r}
# Пропущенных значений нет
colSums(is.na(cu))

# Данные не сбалансированы (размеры групп разные)
table(cu$species)
```

## Изменим названия уровней фактора, чтобы было легче понять о каких птицах речь

```{r, tidy=FALSE}
levels(cu$species)
levels(cu$species) <- c("лес_зав", "луг_кон", "бел_тряс", 
                        "малин", "лес_кон", "крапив")
```

## Задание 1

Дополните код, чтобы построить график зависимости размера яиц кукушек (`length`) от вида птиц-хозяев (`species`), в гнездах которых были обнаружены яйца. На графике должны быть изображены средние значения и их 95% доверительные интервалы, а цвет должен соответствовать виду птиц-хозяев.

```{r eval=FALSE}
theme_set( )
ggplot(data = , aes()) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

```{r gg-mean-conf-limit, echo=FALSE, purl=FALSE}
library(ggplot2)
theme_set(theme_bw())
ggplot(data = cu, aes(x = species, y = length, colour = species)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

## Решение

```{r gg-mean-conf-limit, echo=TRUE, purl=FALSE}
```

## "Некрасивый" порядок уровней на графике

На этом графике некрасивый порядок уровней: средние для разных способов запоминания `cu$species` расположены, как кажется, хаотично.

Порядок групп на графике определяется порядком уровней фактора

```{r purl=FALSE}
# "старый" порядок уровней
levels(cu$species)
```

```{r gg-mean-conf-limit, echo=FALSE, purl=FALSE}
```

## Меняем порядок уровней

Давайте изменим порядок уровней в факторе `cu$species` так, чтобы он соответствовал возрастанию средних значений длины яиц `cu$length`.

```{r}
# "старый" порядок уровней
levels(cu$species)
# переставляем уровни в порядке следования средних значений 
cu$species <- reorder(cu$species, cu$length, FUN = mean)
# "новый" порядок уровней стал таким
levels(cu$species)
```

## График с новым порядком уровней

С новым порядком уровней нам легче визуально сравнивать друг с другом число запомненных слов при разных способах запоминания.

Поскольку, изменив порядок уровней, мы внесли изменения в исходные данные, придется полностью обновить график (т.к.`ggplot()` хранит данные внутри графика).

```{r}
ggplot(data = cu, aes(x = species, y = length, colour = species)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

## Понравившийся график, если понадобится, можно в любой момент довести до ума, а остальные удалить

```{r gg-mean-conf-limit-coloured-labs, purl=FALSE}
ggplot(data = cu, aes(x = species, y = length, colour = species)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal) +
  labs(x = "Вид хозяев", y = "Длина яиц кукушек, мм") + 
  scale_colour_brewer(name = "Вид \nхозяев", palette = "Dark2") + 
  scale_x_discrete(labels = c("Крапивник", "Луговой\nконек", "Малиновка",
"Белая\nтрясогузка", "Лесной\nконек", "Лесная\nзавирушка")) + 
  theme(legend.position = "none")
```

## Множественные сравнения

Мы могли бы сравнить длину яиц в гнездах резных хозяев при помощи t-критерия. У нас всего 6 групп. Сколько возможно между ними попарных сравнений?

```{r gg-mean-conf-limit-coloured-labs, echo=FALSE, purl=FALSE}
```

\pause

Всего возможно 15 сравнений.

Если для каждого сравнения вероятность ошибки первого рода будет $\alpha_{per\ comparison} = 0.05$, то для группы из 15 сравнений --- ?

\pause

$\alpha_{family\ wise} = 0.05 * 15 = 0.75$

Мы рискуем найти различия там где их нет с 75% вероятностью!!!

## Поправка Бонферрони

Если нужно много сравнений, можно снизить $\alpha _{per\ comparison}$ до общепринятого уровня

$$\alpha _{per\ comparison} = \frac{\alpha _{family\ wise}}{n}$$

\vfill
\pause

Например, если хотим зафиксировать $\alpha _{family\ wise} = 0.05$

С поправкой Бонферрони $\alpha _{per\ comparison} = 0.05 / 15 = 0.003$

Это очень жесткая поправка! Мы рискуем не найти достоверных различий, даже там, где они есть...

Но есть выход. Вместо множества попарных сравнений можно использовать один тест --- дисперсионный анализ (analysis of variation, ANOVA).

\vskip0pt plus 1filll

# Линейная модель с одним дискретным предиктором

## Линейная модель с одним дискретным предиктором

<!-- $$y _{ij} = \mu + \alpha _i + \varepsilon _{ij}$$ -->

<!-- - $\alpha$ --- дискретный фактор с _i_ = 1, ..., _I_ группами   -->
<!-- - $\mu$ --- общее среднее   -->
<!-- -_j_ = 1, ..., $J _i$ --- число наблюдений на каждом из уровней фактора   -->

<!-- Чтобы можно было найти параметры такой модели, приходится вводить ограничения одним из способов: -->

<!-- \resizebox{1\textwidth}{!}{ -->
<!-- \begin{tabular}{L{0.2\textwidth} C{0.4\textwidth} C{0.4\textwidth}} -->
<!-- \hline\noalign{\smallskip} -->
<!-- $\mu = 0$ & $\alpha_1 = 0$ & $\sum_i{J_i\alpha_i} = 0$  \\ -->
<!-- \hline\noalign{\smallskip} -->
<!--  & Модель фиктивных переменных & Модель эффектов \\ -->
<!--  & Dummy (indicator) coding = Treatment parametrization = reference cell model &Deviation (effects) coding = Sum to zero parametrization \\ -->
<!--  & по-умолчанию используется в R & часто используется в книгах и в др. программах \\ -->
<!--  & contr.treatment & contr.sum \\ -->
<!-- \hline\noalign{\smallskip} -->
<!-- \end{tabular} -->
<!-- } -->

<!-- ## Модель фиктивных переменных, contr.treatment -->

<!-- Модель $y _{ij} = \mu + \alpha _i + \varepsilon _{ij}$, если  $\alpha_1 = 0$ примет уже знакомую нам форму -->

$$y _{i} = \beta _0 + \beta _1 x _{1i} + \beta _2 x _{2i} + ... + \beta _m x _{mi} + \varepsilon _{i}$$

Коэффициенты линейной модели обозначают отклонения от базового уровня. Такой способ кодирования называется __параметризация фиктивных переменных__ или __параметризация тритментов__ (dummy (indicator) coding = treatment parametrization = reference cell model), и он вам уже знаком по предыдущим двум лекциям. В R этот способ используется по-умолчанию и обозначается __contr.treatment__.

Переменные-индикаторы (= переменные-болванки):

Если у дискретного фактора $k$ уровней, уравнение модели будет включать $m = k - 1$ переменных, кодирующих принадлежность к этим уровням ($x_{1i}, ..., x_{mi}$, i - номер наблюдения). Первый уровень фактора считается базовым и для его кодирования не нужна отдельная переменная.

Коэффициенты:

- $\beta_0$ --- значение свободного члена для базового уровня дискретного фактора (это среднее значение для базового уровня).
- $\beta_1, ..., \beta_m$ --- коррекция свободного члена для других уровней (это отклонения средних для других уровней фактора от базового уровня).

## Задание 2

- Сколько переменных нужно, чтобы записать модель зависимости длины яиц кукушек от вида птиц-хозяев, если использовать параметризацию тритментов?

## Решение:

- Сколько переменных нужно, чтобы записать модель зависимости длины яиц кукушек от вида птиц-хозяев?

- Понадобится 5 переменных, т.к. 6 уровней у фактора `species`

```{r purl=FALSE}
levels(cu$species)
```

Уровень `r levels(cu$species)[1]` будет базовым, и для его кодирования не нужна отдельная переменная).

## Модель с одним дискретным предиктором в матричном виде

Уравнение линейной модели для этого примера (в параметризации фиктивных переменных, contr.treatment):

$$y _{i} = \beta _0 + \beta _1 x _{1i} + \cdots + \beta _5 x _{5i} + \varepsilon _{i}$$

- Здесь $i = 1, ..., n$, т.е. порядковый номер наблюдения,
- $x _{1i}, ..., x _{5i}$ --- переменные-индикаторы для фактора `species`

Если расписать эту формулу, получится по отдельному уравнению для каждого из наблюдений:

$$\begin{aligned}
y_{1} &= \beta_{0} + \beta _1 x _{11} + \cdots + \beta _5 x _{51} + \varepsilon _{1} \\
y_{2} &= \beta_{0} + \beta _1 x _{12} + \cdots + \beta _5 x _{52} + \varepsilon _{2} \\
\vdots \\
y_{n} &= \beta_{0} + \beta _1 x _{1n} + \cdots + \beta _5 x _{5n} + \varepsilon _{n}
\end{aligned}$$

##

Эту систему уравнений

$$\begin{aligned}
y_{1} &= \beta_{0} + \beta _1 x _{11} + \cdots + \beta _5 x _{51} + \varepsilon _{1} \\
y_{2} &= \beta_{0} + \beta _1 x _{12} + \cdots + \beta _5 x _{52} + \varepsilon _{2} \\
\vdots \\
y_{n} &= \beta_{0} + \beta _1 x _{1n} + \cdots + \beta _5 x _{5n} + \varepsilon _{n}
\end{aligned}$$

можно переписать в виде матриц:

$$\begin{bmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{bmatrix} =
\begin{bmatrix}
1 & x_{11} & \cdots & x_{51} \\
1 & x_{12} & \cdots & x_{52} \\
\vdots & & & \\
1 & x_{1n} & \cdots & x_{5n}
\end{bmatrix} \cdot
\begin{bmatrix}
\beta _0 \\ \beta _1 \\ \beta _2 \\ \beta _3 \\ \beta _4 \\ \beta _5
\end{bmatrix} +
\begin{bmatrix}
\varepsilon _1 \\ \varepsilon _2 \\ \vdots \\ \varepsilon _n
\end{bmatrix}$$

##

Для такой длинной формы записи матриц

$$\begin{bmatrix}
y_1 \\ y_2 \\ \vdots \\ y_n
\end{bmatrix} =
\begin{bmatrix}
1 & x_{11} & \cdots & x_{51} \\
1 & x_{12} & \cdots & x_{52} \\
\vdots & & & \\
1 & x_{1n} & \cdots & x_{5n}
\end{bmatrix} \cdot
\begin{bmatrix}
\beta _0 \\ \beta _1 \\ \beta _2 \\ \beta _3 \\ \beta _4 \\ \beta _5
\end{bmatrix} +
\begin{bmatrix}
\varepsilon _1 \\ \varepsilon _2 \\ \vdots \\ \varepsilon _n
\end{bmatrix}$$

есть сокращенная форма записи:

$$\mathbf{Y} = \mathbf{X} \mathbf{\beta} + \mathbf{\varepsilon}$$

- $\mathbf{Y}$ - матрица значений зависимой переменной, один столбец в _n_ строк (_n_ - число наблюдений)
- $\mathbf{X}$ - матрица независимых переменных с _n_ строк, ее первый столбец содержит единицы, далее по столбцу для каждой из переменных в модели
- $\mathbf{\beta}$ - матрица коэффициентов линейной модели, столбец
- $\mathbf{\varepsilon}$ - матрица остатков, один столбец в _n_ строк

## Модельная матрица $\mathbf{X}$ в дисперсионном анализе

Посмотреть своими глазами на эти переменные-индикаторы можно так:

```{r purl=FALSE}
X <- model.matrix(~ species, data = cu)
head(X)
```

## Задание 3

- Подберите линейную модель зависимости длины яиц кукушек в гнездах от вида птиц-хозяев
- Вспомните, что означают коэффициенты этой линейной модели, и вычислите, чему равен ожидаемый размер яиц в гнездах каждого из видов-хозяев.

## Решение:

```{r purl=FALSE}
cmod <- lm(length ~ species, data = cu)
coef(cmod)
```
```{r echo=FALSE}
cf <- round(coef(cmod), 2)
```

Первый коэффициент --- средний размер яиц кукушек в гнездах крапивников (на базовом уровне):

- Крапивник --- $length = b_0 = `r cf[1]`$

Другие коэффициенты --- разницу размеров яиц кукушек в гнездах других хозяев и в гнездах крапивников (отклонения от базового уровня):

- Луговой конек --- $length = b_0 + b_1= `r sum(cf[1:2])`$
- Малиновка --- $length = b_0 + b_2= `r sum(cf[c(1, 3)])`$
- Белая трясогузка --- $length = b_0 + b_3= `r sum(cf[c(1, 4)])`$
- Лесной конек --- $length = b_0 + b_4= `r sum(cf[c(1, 5)])`$
- Лесная завирушка --- $length = b_0 + b_5= `r sum(cf[c(1, 6)])`$


## t-тесты значимости коэффициентов линейной модели с одним дискретным предиктором

\small

- t-тест для первого коэффициента показывает отличается ли от нуля среднее на базовом уровне

- t-тесты значимости других коэффициентов показывают достоверность отличий средних значений в группах от среднего на базовом уровне.

По значениям коэффициентов нельзя сказать влияет ли дискретный фактор целиком (исключение --- фактор с двумя градациями).

```{r}
coef(summary(cmod))
```

\normalsize


# Дисперсионный анализ

```{r purl=FALSE, echo = FALSE, warning=FALSE}
library(dplyr)
dat_smr <- cu %>% group_by(species) %>% summarise(mean = mean(length)) 
dat <- merge(cu, dat_smr)
dat$species <- as.numeric(dat$species) + runif(nrow(dat), -0.15, 0.15)
d_lev <- levels(cu$species)
dat_smr$species <- as.numeric(dat_smr$species)

lims <- range(cu$length) + c(-1, 1)
yannot <- lims[1] + 0.5
set.seed(832)
gmean <- mean(cu$length, na.rm = TRUE)

# 35
id <- 9
Y <- dat$length[id]
Y_hat <-dat$mean[id]
X <- dat$species[id]



pl <- ggplot(data = dat, aes(x = species, y = length)) + theme(legend.position = "none", axis.text.x = element_text(angle = 30, vjust = .8, hjust = .8)) + ylim(lims[1], lims[2]) + scale_x_continuous(breaks = 1:6, labels = d_lev)

# # Общая изменчивость (отклонения от общего среднего)
pl_tot <- pl + 
  geom_segment(aes(xend = species, yend = gmean), colour = "grey70") +
    geom_hline(yintercept = gmean, linetype = "dashed") + 
    geom_point() +
  ggtitle("Общая изменчивость\n(отклонения от общего среднего)") +
    annotate("text", label = "Общее\nсреднее", 
           x = 0,  y = gmean, hjust = -0.1, size = 4) + 
  annotate("text", label = "SS[t] == sum((bar(y) - y[i]))^2", parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6) 

pl_all <- pl + 
  geom_segment(aes(xend = species, yend = gmean), colour = "grey70") +
  geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = "dodgerblue1") + 
  geom_hline(yintercept = gmean, linetype = "dashed") + 
  # annotate("segment", x = X, y = Y, xend = X, yend = gmean, colour = "grey70", size = 2) + 
  annotate("segment", x = X, y = Y, xend = X, yend = Y_hat, colour = "#009E73", size = 2) +
  annotate("segment", x = X, y = Y_hat, xend = X, yend = gmean, colour = "#E69F00", size = 2) +
  geom_point() +
  annotate("text", label = "Общее\nсреднее", 
           x = 0,  y = gmean, hjust = -0.1, size = 4)

pl_no <- pl + 
  geom_hline(yintercept = gmean, linetype = "dashed") + 
  geom_point(data = dat_smr, y = gmean, size = 20, shape = 45, colour = "dodgerblue1") +
    annotate("segment", x = X, y = Y, xend = X, yend = gmean, colour = "grey70", size = 2) + 
  annotate("segment", x = X + 0.05, y = Y, xend = X + 0.05, yend = gmean, colour = "#009E73", size = 2) +
    geom_point() +
  annotate("text", label = "Общее\nсреднее", 
           x = 0,  y = gmean, hjust = -0.1, size = 4)


# library(plyr)
# Межгрупповая изменчивость (связанная с фактором)
pl_x <- pl + 
  geom_hline(aes(yintercept = gmean), linetype = "dashed") + 
  geom_segment(data = dat_smr, aes(x = species, y = mean, xend = species, yend = gmean), colour = "#E69F00", size = 2) +
  geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = "dodgerblue1") + 
    geom_point() +
  ggtitle("Факторная изменчивость\n(межгрупповая)")+
    annotate("text", label = "SS[x] == sum((bar(y) - hat(y)[i]))^2", parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6)

# Внутригрупповая изменчивость (случайная)
pl_res <- pl + 
  geom_segment(data = dat, aes(xend = species, yend = mean), colour = "#009E73") +
    geom_hline(yintercept = gmean, linetype = "dashed") + 
    geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = "dodgerblue1") + 
    geom_point() +
  ggtitle("Случайная изменчивость\n(внутригрупповая)")+
    annotate("text", label = "SS[e] == sum(sum((y [i] - hat(y)[i])))^2", parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6)
```

## Общая изменчивость

Общая изменчивость SS~t~ --- это сумма квадратов отклонений наблюдаемых значений $y_i$ от общего среднего $\bar y$

```{r gg-tot, echo=FALSE, fig.height=3.5, purl=FALSE}
pl_tot
```

## Отклонения от общего среднего

Отклонения от общего среднего складываются из двух составляющих:

- Внутригрупповые отклонения --- отклонения наблюдаемых значений от внутригрупповых средних
- Межгрупповые отклонения --- отклонения внутригрупповых средних от общего среднего ("эффекты" групп)

```{r gg-all, echo=FALSE, fig.height=3, purl=FALSE}
pl_all
```

## Структура общей изменчивости

Общая изменчивость $SS_t$ складывается из изменчивости связанной с фактором $SS_x$ и случайной изменчивости $SS_e$

$$SS_t = SS_x + SS_e$$

```{r gg-ss, echo=FALSE, fig.height=3.5, fig.width=10, purl=FALSE}
library(gridExtra)
grid.arrange(pl_tot, pl_x, pl_res, nrow = 1)
```

## Средние квадраты отклонений

Если поделить суммы квадратов отклонений ($SS$) на их число степеней свободы, то получатся средние квадраты отклонений ($MS$) --- дисперсии

```{r gg-ss, echo=FALSE, fig.height=3, fig.width=10, purl=FALSE}
```


\resizebox{1\textwidth}{!}{
{\small
\begin{tabular}{c c c}
\hline\noalign{\smallskip}
$MS_t$ полная дисперсия  & 
$MS_x$ факторная дисперсия & 
$MS_e$ остаточная дисперсия  \\
\hline\noalign{\smallskip}
$MS_{t} =\frac{SS_{t}}{df_{t}}$ & $MS_{x} =\frac{SS_{x}}{df_{x}}$ & $MS_{e} =\frac{SS_{e}}{df_{e}}$ \\
$SS_{t}=\sum{(\bar{y}-y_i)^2}$ & $SS_{x}=\sum{(\hat{y}-\bar{y})^2}$ & $SS_{e}=\sum{(\hat{y}-y_i)^2}$ \\
$df_{t} = N - 1$ & $df_{x} = a - 1$ & $df_{e} = N - a$  \\
\hline\noalign{\smallskip}
\end{tabular}
}
}



##  Если выборки из одной совокупности, то  

Если выборки из одной совокупности, то наблюдения из разных групп будут отличаться друг от друга не больше, чем наблюдения из одной группы,  
т.е. факторная дисперсия будет близка к случайной дисперсии $MS_x \sim MS_e$. Их равенство можно проверить при помощи F-критерия

$$ F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$$


```{r gg-ss, echo=FALSE, fig.height=3.5, fig.width=10, purl=FALSE}
```

## F-критерий

$$ F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$$
Гипотезы: 

$H _0$: все выборки взяты из одной совокупности --- $\bar X_1 = \bar X_2  = \dots = \bar X_a$. Тогда $MS _x = MS _e$

$H _A$: какая-то из выборок из другой совокупности, т.е. какое-то среднее значение $\bar X_i$ отличается от других. Тогда $MS _x \ne MS _e$

F-статистика подчиняется F-распределению. Форма F-распределения зависит от двух параметров: $df_{x} = a - 1$ и $df_{e} = N - a$

```{r f-distribution, echo=FALSE, purl=FALSE, fig.width=7, fig.height=2}
library(car)
df_1 <- 5
df_2 <- 114
F_val <- Anova(cmod)[1, 3]
F_crit <- qf(p = 0.05, df1 = df_1, df2 = df_2, lower.tail = F)

dfr <- data.frame(f = seq(-0.3, 9, 0.01))
ggplot(dfr, aes(x = f)) + 
  stat_function(fun = df, args = list(df1 = df_1, df2 = 114), size = 1.3) + 
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = qf(p = 0.95, df1 = df_1, df2 = 114), color = "red", linetype = "dashed") + 
  annotate("text", label = "F при α = 0.05", x = qf(p = 0.95, df1 = df_1, df2 = 114), y = 1, hjust = 1.1) +
  geom_vline(xintercept = 8.0523, linetype = "dashed") +
  annotate("text", label = "F", x = F_val, y = 1, hjust = -1) +
  labs(title = paste0("F-распределение, df1 = ", df_1, ", df2 = ", df_2), x = "F", y = "Плотность вероятности") + theme_bw(base_size = 10)
```


## Таблица дисперсионного анализа 

\resizebox{1\textwidth}{!}{
\begin{tabular}{L{2.2cm} c c c c}
\hline\noalign{\smallskip}
Источник \linebreak[2] изменчивости  & SS & df & MS & F  \\
\hline\noalign{\smallskip}
Название фактора & $SS _x = \sum{(\bar y - \hat y _i)^2}$ & $df _x = a - 1$ & $MS _x = \frac{SS _x}{df _x}$ & $F _{df _x df _e} = \frac{MS _x}{MS _e}$ \\
Случайная & $SS _e = \sum{(y _i - \hat y _i)^2}$ & $df _e = N - a$ & $MS _e = \frac{SS _e}{df _e}$ \\
Общая & $SS _t = \sum {(\bar y - y _i)^2}$ & $df _t = N - 1$ & & \\
\hline\noalign{\smallskip}
\end{tabular}
}

\large Минимальное упоминание результатов в тексте должно содержать $F _{df _x, df _e}$ и $p$.


## Делаем дисперсионный анализ в R

В R есть много функций для дисперсионного анализа. Мы рекомендуем `Anova()` (__с большой буквы__) из пакета `car`. Зачем? Эта функция умеет тестировать влияние факторов в определенном порядке. Когда факторов будет больше одного, это станет важно для результатов.

```{r, message=FALSE}
library(car)
cu_anova <- Anova(cmod)
cu_anova
```

## Результаты дисперсионного анализа

Результаты дисперсионного анализа можно описать в тексте:

```{r, echo=FALSE}
result <- cu_anova
dfs <- paste0(result$Df, collapse= ",")
fval <- round(result$'F value'[1], 2)
sign <- ifelse(result$'Pr(>F)'[1] <= 0.01, "$p < 0.01$", ifelse(result$'Pr(>F)'[1] <= 0.05, "$p < 0.05$", ""))
```

> - Длина яиц кукушек в гнездах разных птиц-хозяев достоверно различается ($F _{`r dfs`} = `r fval`$, `r sign`).

## Результаты дисперсионного анализа

Результаты дисперсионного анализа можно представить в виде таблицы

- Длина яиц кукушек достоверно различалась в гнездах разных птиц-хозяев (Табл. \autoref{tab:one-anova}).

```{r echo=FALSE, results='asis', purl=FALSE}
library(xtable)
smr <- fix_Anova(cu_anova,
                 rown = c("Хозяин", "Остаточная"), 
                 coln = c("SS", "df", "F", "P"))
xtb <- xtable(
  smr,
  caption = "Результаты дисперсионного анализа длины яиц кукушек в гнездах разных птиц-хозяев. SS --- суммы квадратов отклонений, df --- число степеней свободы, F --- значение F-критерия, P --- доверительная вероятность.",
  label = "tab:one-anova")
print.xtable(xtb, comment = F, caption.placement = "top")
```

# Условия примененимости дисперсионного анализа

## Результатам тестов можно верить, если выполняются условия применимости

Условия применимости дисперсионного анализа:

- Случайность и независимость  наблюдений внутри групп
- Нормальное распределение остатков
- Гомогенность дисперсий остатков
- Отсутствие колинеарности факторов (независимость групп)

### Другие ограничения:

- Лучше работает, если размеры групп примерно одинаковы (т.наз. сбалансированный дисперсионный комплекс)
- Устойчив к отклонениям от нормального распределения (при равных объемах групп или при больших выборках)

## Проверяем выполнение условий применимости

```{r}
# Данные для графиков остатков
cmod_diag <- fortify(cmod)
```
### 1) График расстояния Кука

```{r}
ggplot(cmod_diag, aes(x = 1:nrow(cmod_diag), y = .cooksd)) +
  geom_bar(stat = "identity")
```

- Выбросов нет

## 2) График остатков от предсказанных значений

```{r eval=FALSE, purl=FALSE}
ggplot(cmod_diag, aes(x = .fitted, y = .stdresid)) + geom_jitter()
```

У нас один единственный дискретный предиктор, поэтому удобнее сразу боксплот


### 3) Графики остатков от предикторов в модели и не в модели

```{r}
ggplot(cmod_diag, aes(x = species, y = .stdresid)) + geom_boxplot()
```
- Дисперсии почти одинаковые. Может быть, в одной из групп чуть больше

## 4) Квантильный график остатков
```{r}
library(car)
qqPlot(cmod)
```

- Распределение остатков отличается от нормального

# Пост хок тесты

## Как понять, какие именно группы различаются

Дисперсионный анализ говорит нам только, есть ли влияние фактора, но не говорит, какие именно группы различаются.

Коэффициенты линейной модели в `summary(cmod)` содержат лишь часть ответа --- сравнение средних значених всех групп со средним на базовом уровне.

Если нас интересуют другие возможные попарные сравнения, нужно сделать пост хок тест.

## Post hoc тесты

Пост хок тесты --- попарные сравнения средних __после того, как дисперсионный анализ показал, что влияние фактора достоверно__

### Свойства post hoc тестов:

- __Применяются, только если влияние фактора значимо__
- Делают поправку для снижения вероятности ошибки I рода $\alpha$, (но не слишком большую, чтобы не
снизилась мощность, и чтобы не возросла вероятность ошибки II рода $\beta$)
  - Учитывают величину различий между средними
  - Учитывают количество сравниваемых пар
- Различаются по степени консервативности (тест Тьюки --- разумный компромисс) 
- Работают лучше при равных объемах групп, при гомогенности дисперсий

## Пост хок тест Тьюки в R

- `glht()` --- "general linear hypotheses testing"
- `linfct` --- аргумент, задающий гипотезу для тестирования

- `mcp()` --- функция, чтобы задавать множественные сравнения (обычные пост хоки)
- `species` = "Tukey" --- тест Тьюки по фактору `species`

```{r, message=FALSE}
library(multcomp)
cu_ph <- glht(cmod, linfct = mcp(species = "Tukey"))
```

## Результаты попарных сравнений (тест Тьюки) {.smaller}

Таблица результатов пост хок теста практически нечитабельна. 
\small

```{r}
summary(cu_ph)
```

## Результаты пост хок теста

Результаты пост хок теста можно привести в виде текста...

- Размер яиц кукушек в гнездах крапивника достоверно меньше, чем в гнездах лугового конька (тест Тьюки, $p < 0.01$). Размер яиц кукушек в гнездах лесной завирушки, белой трясогузки, малиновки и лесного конька не различается, но яйца в гнездах этих видов крупнее, чем у лугового конька или крапивника (тест Тьюки, от $p < 0.01$ до $0.05$).

...или построить график

## Данные для графика при помощи `predict()`

```{r}
MyData <- data.frame(
  species = factor(levels(cu$species), 
                   levels = levels(cu$species)))

MyData <- data.frame(
  MyData, 
  predict(cmod, newdata = MyData, interval = "confidence")
  )

MyData
```

## Задание 4

Создайте MyData вручную:

- предсказанные значения 
- стандартные ошибки
- верхнюю и нижнюю границы доверительных интервалов

```{r eval=FALSE}
MyData <- data.frame(
  species = factor(levels(cu$species), 
                   levels = levels(cu$species)))

X <- model.matrix()
betas <- 
MyData$fit <-  %*% 
MyData$se <- sqrt(diag(X %*% vcov(cmod) %*% t(X)))
MyData$lwr <- MyData$ - 1.96 * MyData$
MyData$upr <- MyData$ + 1.96 * MyData$

```

## Решение:

```{r purl=FALSE}
MyData <- data.frame(
  species = factor(levels(cu$species), 
                   levels = levels(cu$species)))
X <- model.matrix(~species, data = MyData)
betas <- coef(cmod)
MyData$fit <- X %*% betas
MyData$se <- sqrt(diag(X %*% vcov(cmod) %*% t(X)))
MyData$lwr <- MyData$fit - 1.96 * MyData$se
MyData$upr <- MyData$fit + 1.96 * MyData$se
MyData
```

## Столбчатый график

```{r}
gg_bars <- ggplot(data = MyData, aes(x = species, y = fit)) + 
  geom_bar(stat = "identity", aes(fill = species), width = 0.5) +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.1) + 
  labs(x = "Вид хозяев", y = "Длина яиц кукушек, мм") +
  scale_fill_brewer(name = "Вид \nхозяев", palette = "Dark2") + 
  scale_x_discrete(labels = c("Крапивник", "Луговой\nконек", "Малиновка",
                            "Белая\nтрясогузка", "Лесной\nконек", "Лесная\nзавирушка")) + 
  theme(legend.position = "none")
gg_bars
```

## Можно привести результаты пост хок теста на столбчатом графике

Достоверно различающиеся группы обозначим разными буквами

```{r}
gg_bars_coded <- gg_bars + 
  geom_text(aes(y = 1.6,  label = c("A", "B", "BC", "BC", "C", "C")), 
            colour = "white", size = 7)
gg_bars_coded
```


## Take home messages

- Дисперсионный анализ --- линейная модель с дискретными предикторами, существует в нескольких параметризациях, которые отличаются трактовками коэффициентов
- При помощи дисперсионного анализа можно проверить гипотезу о равенстве средних значений в группах
- Условия применимости дисперсионного анализа
    - Случайность и независимость групп и наблюдений внутри групп
    - Нормальное распределение в группах
    - Гомогенность дисперсий в группах
- При множественных попарных сравнениях увеличивается вероятность ошибки первого рода, поэтому нужно вносить поправку для уровня значимости
- Post hoc тесты --- это попарные сравнения после дисперсионного анализа, которые позволяют сказать, какие именно средние различаются

## Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 173--207
- Logan, 2010, pp. 254--282
- [Open Intro to Statistics](http://www.openintro.org/stat/), pp.236--246 
- Sokal, Rohlf, 1995, pp. 179--260
- Zar, 2010, pp. 189-207
