---
title: "Краткое введение в мир матричной алгебры"
subtitle: "Линейные модели..."
author: "Вадим Хайтов, Марина Варфоломеева"
output:
  ioslides_presentation:
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
    widescreen: yes
---

## Вы сможете
- Объяснить что такое матрицы и какие бывают их основные разновидности
- Выполнить базовые операции с матрицами с использованием функций R
- Применить в среде R методы матричной алгебры для решения простейших задач




```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

##Решите задачу 
В популяции некоторого организма в момент времени $t_1$ представлено четыре возрастные группы:

| Возрастаная группа| Количество особей |
|:-----------------:|:-----------------:|
|         0+        |        100        |
|         1+        |         10        |
|         2+        |         5         |
|         3+        |         1         |

---

Какова будет численность возрастных групп в момент времени $t_2$ если известно, что

1. каждая особь возрастом 2+ оставляет 10 потомков, а каждая особь возрастом 3+ - 20 потомков.
2. вероятность выживания особей при переходе от $t_1$ к $t_2$ опсывается следующими величинами

| Переход из  младшей группы в старшую | Вероятность выживания |
|:------------------------------------:|:---------------------:|
|                0+ - 1+               |          0.1          |
|                1+ - 2+               |          0.5          |
|                2+ - 3+               |          0.3          |


## Простое, но нерациональное решение

| Возрастаня группа | Количество особей в момент времени $t_2$ |
|-------------------|------------------------------------------|
| 0+                | $5 \cdot 10 + 1 \cdot 20 = 70$                |
| 1+                | $100 \cdot 0.1 = 10$                          |
| 2+                | $10 \cdot 0.5 = 5$                           |
| 3+                | $5 \cdot 0.3 = 1.5$                            |


## Рациональное решение

Демографический вектор в момент времени $t_1$
```{r}
t1 <- c(100, 10, 5, 1)
t1
```

## Рациональное решение


Демографическая матрица Лесли


$$
\begin{pmatrix}
F_1 & F_2 & F_3 & F_4 \\
P_{0+ -1+}& 0 & 0 & 0  \\
0 & P_{1+-2+} & 0 & 0  \\
0 & 0 & P_{2+-3+} & 0  \\
\end{pmatrix}
$$

```{r}
lesley <- matrix(c(c(0, 0, 10, 20), c(0.1, 0, 0, 0), c(0, 0.5, 0, 0), c(0, 0, 0.3, 0)), nrow = 4, byrow = T)

lesley
```

## ## Рациональное решение - решение средствами матричной алгебры

```{r}
lesley %*% t1
```


# Зачем нужны матрицы?

##Матричные объекты
- Есть много типов объектов, для которых такое выражение оказывается наиболее естественным (изображения, описания многомерных объектов и т.д.)
- В матрицах, как и в обычных числах, скрыта информация, которую можно извлекать и преобразовывать по определенным правилам


## Структура матриц

$$\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1c} \\
a_{21} & a_{22} & \cdots & a_{2c} \\    
\vdots & \vdots & \ddots & \vdots \\
a_{r1} & a_{r2} & \cdots & a_{rc}
\end{pmatrix}
    $$

Размер (порядок) матрицы $r \times c$ 

## Разновидности матриц 

Вектор-строка (row matrix)

$$ 
\textbf {A} =
\begin{pmatrix}
1 & 2 & 3 
\end{pmatrix}
$$


Вектор-столбец (column matrix)

$$ 
\textbf {B} =
\begin{pmatrix}
1 \\
4 \\    
7 \\
10 
\end{pmatrix}
$$

## Разновидности матриц 

Прямоугольные матрицы (rectangular matrices)

$$ 
\textbf {C} =
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\    
7 & 8 & 9 \\
10 & 11 & 12 
\end{pmatrix}
$$



$$ 
\textbf {D} =
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6     
\end{pmatrix}
$$

В таком виде обычно представляются исходные данные

##Квадратные матрицы (square matrices)

Это наиболее "операбельные" матрицы

$$ 
\textbf {E} =
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\    
7 & 8 & 9 
\end{pmatrix}
$$

Диагональные матрицы (diagonal matrix)

$$ 
\textbf {F} =
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 5 & 0 & 0 \\    
0 & 0 & 9 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix}
$$


<!-- ##Квадратные матрицы (square matrices) -->

<!-- Треугольные матрицы (triangular matrices) -->
<!-- $$ \textbf {H} = -->
<!-- \begin{pmatrix} -->
<!-- 1 & 2 & 3 & 4 \\ -->
<!-- 0 & 5 & 6 & 7 \\     -->
<!-- 0 & 0 & 9 & 10 \\ -->
<!-- 0 & 0 & 0 & 1 -->
<!-- \end{pmatrix} -->
<!-- $$ -->

<!-- или -->

<!-- $$  -->
<!-- \textbf {H} = -->
<!-- \begin{pmatrix} -->
<!-- 1 & 0 & 0 & 0 \\ -->
<!-- 3 & 5 & 0 & 0 \\     -->
<!-- 4 & 7 & 9 & 0 \\ -->
<!-- 5 & 8 & 10 & 11 -->
<!-- \end{pmatrix} -->
<!-- $$ -->

##Квадратные матрицы (square matrices)

Единичная матрица (identity matrix)
$$ 
\textbf {I} =
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\    
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix}
$$



Единичная матрица (обозначение $\textbf{I}$) занимают особое место в матричной алгебре.   
Она выполняет ту же роль, которую выполняет единица в обычной алгебре. 




##Особенность квадратных матриц

Для квадратных матриц могут быть найдены (но не обязательно существуют) некоторые важные для матричной алгебры показатели: *определитель*, *инверсия*, *собственные значения* и *собственные векторы*




##Задание

Создайте с помощью R следующую матрицу

$$ 
\begin{pmatrix}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\    
9 & 10 & 11 & 12 \\
\end{pmatrix}
$$
##Решение

```{r, echo=FALSE}
matrix(1:12, ncol = 3, byrow = TRUE)
```

##Задание

Создайте с помощью R единичную матрицу

$$ 
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\    
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 
\end{pmatrix}
$$

## Решение

```{r, echo=FALSE, purl = FALSE}
diag(rep(1,5))
```

#Операции с матрицами

##Транспонирование матриц

```{r}
A <- matrix(1:12, ncol = 3)
A
```

Транспонированная матрица $\textbf{A}$
```{r}
B <- t(A)
B
```

##Сложение матриц
```{r, purl = FALSE}
A + 4
```

```{r, purl = FALSE}
A + A
```

Но! Нельзя складывать матрицы разных размеров
```{r, eval=FALSE, purl = FALSE}
A + B
```

##Биологическое приложение
Предположим, что мы подсчитывали двумя разными методами крупных и мелких животных  трех  видов в одних и тех же пробах

```{r, echo = FALSE, purl = T}
Large <- data.frame(Sp1 = round(rnorm(5, 10, 2)), Sp2 = round(rnorm(5, 10, 3)), Sp3 = round(rnorm(5, 10, 2))) 

rownames(Large) <- c("Sample1", "Sample2", "Sample3", "Sample4", "Sample5" )

Small <- data.frame(Sp1 = round(rnorm(5, 50, 5)), Sp2 = round(rnorm(5, 50, 5)), Sp3 = round(rnorm(5, 50, 5))) 

rownames(Small) <- c("Sample1", "Sample2", "Sample3", "Sample4", "Sample5" )
```


```{r, echo=FALSE, purl = FALSE}
Large
Small
```

##Биологическое приложение

Общее обилие 
```{r, purl = T}
Large + Small
```


##Простое умножение 
Умножение на число
```{r, purl = FALSE}
A * 4
```

Простое умножение матрицы на вектор возможно только если число элементов в векторе равно числу строк в матрице

```{r, purl = FALSE}
A * c(10, 11, 12, 13)
```

Все элементы первой строки матрицы умножаются на первый элемент вектора, все элементы второй строки на второй элемент вектора и т.д.  


##Биологическое применение
Допустим, учет организмов в части описаний проходил не на всей выборке, а лишь в ее части.
```{r, purl = T}
Rpocessed_portion <- c(1, 1, 1/2, 1/3, 1/4)
Processed_Factor <- 1/Rpocessed_portion
```

```{r, purl = T}
Small * Processed_Factor
```


##  Скалярное произведение векторов   
Допустимо только для векторов одинаковой размерности

$$
\textbf{a} \bullet \textbf{b} =  
\begin{pmatrix}
a_1 \\
a_3 \\    
a_4 \\
a_5 \\
a_6 \\
a_7
\end{pmatrix}
\times
\begin{pmatrix}
b_1 &
b_3 &    
b_4 &
b_5 &
b_6 &
b_7
\end{pmatrix}
= x
$$

Результат этой операции - число (скаляр)


##Биологическое применение
Сколько особей родится в популяции, если мы знаем репродуктивные характеристики всех возрастных групп?
$$
\begin{pmatrix}
N_1 \\
N_3 \\    
N_4 \\
N_5 \\
N_6 \\
N_7
\end{pmatrix}
\times
\begin{pmatrix}
F_1 & F_2 & F_3 & F_4 & F_5 & F_6 & F_7
\end{pmatrix}
$$

```{r}
N <- c(20, 40, 32, 45, 80, 50, 10)
Fert <- c( 0,  0,   1,   2,   2,   0,   0)
t(N) %*% (Fert)

```


##Умножение матриц
Умножать можно только в том случае, если число строк одной матрицы равно числу столбцов другой матрицы

```{r}
A %*% B

```

```{r}
A %*% t(A)
```


НО! Нельзя произвести такое умножение
```{r, eval=FALSE}
A %*% A
```




##Биологическое применение
Простейший пример использования умножения матриц - построение модели динамики демографической структуры популяции
Для вычислений необходим начальный *демографический вектор* и *матрица Лесли*

$$
\begin{pmatrix}
F_1 & F_2 & F_3 & F_4 & F_5 & F_6 & F_7 \\
P_{1-2}& 0 & 0 & 0 & 0 & 0 & 0 \\    
0 & P_{2-3} & 0 & 0 & 0 & 0 & 0 \\    
0 & 0 & P_{3-4} & 0 & 0 & 0 & 0 \\    
0 & 0 & 0 & P_{4-5} & 0 & 0 & 0 \\    
0 & 0 & 0 & 0 & P_{5-6} & 0 & 0 \\    
0 & 0 & 0 & 0 & 0 & P_{6-7} & 0     
\end{pmatrix}
\times
\begin{pmatrix}
N1_t \\
N3_t \\    
N4_t \\
N5_t \\
N6_t \\
N7_t
\end{pmatrix}
=
\begin{pmatrix}
N1_{t+1} \\
N3_{t+1} \\    
N4_{t+1} \\
N5_{t+1} \\
N6_{t+1} \\
N7_{t+1}
\end{pmatrix}
$$

##Простейшая демографическая модель


```{r, echo=FALSE}
T1 <- c(20, 40, 32, 45, 80, 50, 10)
Age <- c("0", "1-10", "11-20", "21-35", "36-45", "46-55", "56-65")
Pop <- data.frame(Age, T1)
```


Демографический вектор в момент времени $t$ 
```{r, echo=FALSE}
Pop

```

Матрица Лесли
```{r, echo=FALSE}
Lesl <- matrix(
c( 0,  0,   1,   2,   2,   0,   0,
  0.6, 0,   0,   0,   0,   0,   0,
   0,  0.7, 0,   0,   0,   0,   0, 
   0,  0,   0.8, 0,   0,   0,   0,
   0,  0,   0,   0.7, 0,   0,   0,
   0,  0,   0,   0,   0.6, 0,   0,
   0, 0,    0,   0,   0,  0.2, 0  ),
byrow = T, 
ncol = 7)
Lesl
```

## Демографическая струкутра в момент времени $t+1$ 


```{r}
Pop$T2 <- as.vector( Lesl %*% (Pop$T1 ))
Pop$T3 <- as.vector( Lesl %*% (Pop$T2 ))
Pop$T4 <- as.vector( Lesl %*% (Pop$T3 ))
Pop$T5 <- as.vector( Lesl %*% (Pop$T4 ))
Pop$T6 <- as.vector( Lesl %*% (Pop$T5 ))
Pop$T7 <- as.vector( Lesl %*% (Pop$T6 ))
Pop$T8 <- as.vector( Lesl %*% (Pop$T7 ))
Pop$T9 <- as.vector( Lesl %*% (Pop$T8 ))
Pop$T10 <- as.vector( Lesl %*% (Pop$T9 ))

```

## Демографическая струкутра в момент времени $t+1$ 

```{r, echo=FALSE, message=FALSE, fig.width=6, fig.height=6}
library(ggplot2)
library(reshape)
Pop2 <- melt(Pop)
ggplot(Pop2, aes(x=Age, y = value)) + geom_bar(stat = "identity") + facet_wrap(~variable, ncol = 2) + labs(x = "Возраст", y = "Число особей")
```


## Вычисление корреляций через произведение матриц

$$
\bf{Cor} = \frac{\bf{{X}'_{stand}}\bf{X_{stand}}}{N-1}

$$

Используем известные нам данные по размеру головного мозга


```{r}
brain <- read.csv("data/IQ_brain.csv", header = TRUE)
br <- brain[complete.cases(brain), -1]
br <- as.matrix(br)
br_scaled <- scale(br) #Стандартизуем значения

t(br_scaled) %*% br_scaled / (nrow(br_scaled) - 1) 

```



##Некоторые свойства произведения матриц
1) Если существует произведение матриц $\textbf{BC}$, то не обязательно существует $\textbf{CB}$

```{r}
B <- matrix(1:24, ncol = 4)
C <- matrix(1:12, ncol = 3)

B %*% C
```

HO!

```{r, eval=FALSE}

C %*% B
```

Такое произведение невозможно

##Некоторые свойства произведения матриц
2) Всегда существует такое произведение матриц $\textbf{CС'}$ и $\textbf{C'С}$

```{r}
C %*% t(C)
```

```{r}
t(C) %*% C
```


##Некоторые свойства произведения матриц
3) Произведение матриц $\textbf{BC}$ как правило не равно $\textbf{CB}$
```{r}
B <- matrix(1:9, ncol = 3)
C <- matrix(11:19, ncol = 3)

B %*%  C

C %*% B
```

##Некоторые свойства произведения матриц
4)  $[\textbf{BC}]' = \textbf{C}'\textbf{B}'$
```{r}
t(B %*% C)
```

```{r}
t(C) %*% t(B)
```

##Некоторые свойства произведения матриц
5)  Произведение $\textbf{BB'}$ и $\textbf{B'B}$ всегда дает симметричную матрицу

```{r}
B %*% t(B)
```

```{r}
t(B) %*% B

```



##Определитель матрицы
Определитель матрицы - это некоторое число.

По значению этого числа можно *определить* есть ли у матрицы некоторые свойства (например, обратима ли матрица).

Определитель бывает только у квадратных матриц.

Матрицы, имеющие определитель равный нулю, называются *сингулярными* матрицами.

```{r}
det(B)
```



```{r}
BB <- t(B) %*% B
det(BB)
```






##Обращение (инверсия) матриц 

В матричной алгебре нет процедуры деления. Вместо нее используют обращение матриц.

$$
\textbf{X}^{-1}\textbf{X} = \textbf{I}
$$
Произведение инверсии матрицы и исходной матрицы дает единичную матрицу


##Обращение (инверсия) матриц 

Только некоторые квадратные матрицы, могут иметь обратную матрицу. 

Поэтому для квадратных матриц  справедливо $\textbf{X} \textbf{X}^{-1} = \textbf{X}^{-1} \textbf{X}$

##Обращение (инверсия) матриц 
Для матриц, определитель которых равен нулю, обратной матрицы не существует



##Решение в среде R
Создадим матрицу
```{r, echo=FALSE}
X <- matrix(c(seq(1, 8),10), nrow = 3, byrow = T)
X

```

Ее определитель
```{r}
det(X)

```

##Решение в среде R
Обратная матрица 
```{r}
solve(X)
```

По определению, $\textbf{X}^{-1}\textbf{X} = \textbf{I}$
```{r}
round(solve(X) %*% X )

```


#Примнение обращенных матриц 

##Решение систем линейных уравнений

Простейший случай использования обратных матриц - решение систем линейных уравнений
$$
\begin{cases}
1x + 2y + 3z = 2\\  
4x + 5y + 6z = 4 \\  
7x + 8y + 10z = 10   
\end{cases}
$$

Эту систему можно представить в матричном виде

$$
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 10
\end{pmatrix}
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
=
\begin{pmatrix}
2 \\ 4 \\ 10
\end{pmatrix}
$$

Тогда 

$$
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
=
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 10
\end{pmatrix}
^{-1}
\begin{pmatrix}
2 \\ 4 \\ 10
\end{pmatrix}
$$

##Задание 
Решите приведенную систему уравнений с использованием матричной алгебры 

$$
\begin{cases}
1x + 2y + 3z = 2\\  
4x + 5y + 6z = 4 \\  
7x + 8y + 10z = 10   
\end{cases}
$$



##Решение

```{r}
Coef <- matrix(c(1 , 2 , 3 ,
         4 , 5 , 6 ,
         7 , 8 , 10), byrow = T, ncol = 3)
Val <- c(2,4,10)

solve(Coef) %*% Val
```

##Проверим
```{r}
round(1*3.33 + 2*-6.67 + 3*4.00)
round(4*3.33 + 5*-6.67 + 6*4.00)
round(7*3.33 + 8*-6.67 + 10*4.00)


```



#Подбор параметров линейной регрессии методом наименьших квадратов с использованием матричной алгебры

##Линейная регрессия в матричном виде

При подборе коэффициентов методом наименьших квадратов нам надо решить следующее матричное уравнение:

$$
\textbf{y} =  \textbf{X} \pmb{\beta}
$$


Здесь  

$\textbf{y}$ - вектор предсказанных значений      

$\textbf{X}$ - модельная матрица  $\begin{pmatrix} 1 & x_1  \\ 1 & x_2 \\ \vdots & \vdots \\ 1 & x_n \end{pmatrix}$   

$\pmb{\beta}$  - вектор коэффициентов модели $b_0 + b_1x$





##Решение этого уравнения   

Умножим обе части уравнения на транспонированную матрицу $\textbf{X}'$  

$$ \textbf{X}'  \textbf{y} = \textbf{X}'\textbf{X} \pmb{\beta}$$

Матрица $\textbf{X}'\textbf{X}$ - это всегда квадратная матрица. Ее можно обратить.

Тогда
$$
\pmb{\beta} = [\textbf{X}'\textbf{X}]^{-1}[\textbf{X}'\textbf{y}]
$$


##Подбираем коэффициенты с помощью фунции `lm()`
```{r}
data(cars)
Mod <- lm(dist ~ speed, data = cars)
summary(Mod)

```

##Коэффициенты модели
```{r}
coefficients(Mod)
```


##Графическое отражение, построенное с помощью `geom_smooth()`
```{r}
library(ggplot2)
theme_set(theme_bw())
ggplot(cars, aes(x = speed, y = dist)) + geom_point() + geom_smooth(method = "lm")

```



##Вычисление коэффициентов линейной регрессии вручную

Находим вектор коэффициентов на основе уравнения $\pmb{\beta} = [\textbf{X}'\textbf{X}]^{-1}[\textbf{X}'\textbf{y}]$

```{r}
X <- model.matrix(~speed, data = cars)
Y <- cars$dist
betas <- solve(t(X) %*% X) %*% (t(X) %*% Y)
betas

```


<!-- ##Вычисление вариационно-ковариационной матрицы  -->
<!-- Подобранные параметры - это лишь _оценки_ некоторых параметров, описывающих связь между зависимой переменной и предиктором в популяции.     -->

<!-- Варьирование параметров описывает *вриацонно-ковариационная матрица*.     -->

<!-- В среде `R`, если модель задана, например, с помощью функции `lm()`, эта матрица вычисляется так    -->

<!-- ```{r} -->
<!-- vcov(Mod) -->
<!-- ``` -->



<!-- ##Вычисление вариационо-ковариационной матрицы вручную -->

<!-- $$ -->
<!-- \textbf{V}(\pmb{\beta}) = s^2[\textbf{X}'\textbf{X}]^{-1} -->
<!-- $$ -->
<!-- где -->

<!-- $$ -->
<!-- s^2 = \frac{\sum\limits_{\substack{i=1}}^n e_i^2}{n-k} -->
<!-- $$ -->

<!-- $\sum\limits_{\substack{i=1}}^n e_i^2$ - сумма квадратов остатков    -->
<!-- $n$ - объем выборки    -->
<!-- $k$ - число параметров в модели -->

<!-- ##Вычисление вариационо-ковариационной матрицы вручную -->
<!-- Вычисляем $\sum\limits_{\substack{i=1}}^n e_i^2$    -->

<!-- ```{r} -->
<!-- predict_values <- X %*% betas -->

<!-- resid_values <- cars$dist - predict_values -->

<!-- s2 <- sum(resid_values^2)/(length(resid_values) - length(betas)) -->

<!-- s2 -->
<!-- ``` -->

<!-- ##Вычисление вариационо-ковариационной матрицы вручную -->
<!-- Вычисляем вариационно-ковариационную матрицу -->

<!-- $$ -->
<!-- \textbf{V}(\pmb{\beta}) = s^2[\textbf{X}'\textbf{X}]^{-1} -->
<!-- $$ -->

<!-- ```{r} -->
<!-- covbetas <- s2 * solve(t(X) %*% X) -->
<!-- covbetas -->
<!-- ``` -->


##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 1. Формируем искусственный датасет со всеми возможными значениями предиктора

```{r}
MyData <- data.frame(speed = seq(min(cars$speed), max(cars$speed)))
head(MyData)
```

##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 2. Формируем модельную матрицу для искусственно созданных данных

```{r}
X2 <- model.matrix( ~ speed, data = MyData)
head(X2)

```

##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 3. Вычисляем предсказанные значения для искусственно созданных данных
```{r}
MyData$Predicted <- X2 %*% betas
```

##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 4. Рисуем график
```{r}
library(ggplot2)
ggplot(MyData, aes(x = speed, y = Predicted)) + geom_line() + geom_point(data = cars, aes(x = speed, y = dist))
```


Осталось нанести границы доверительной области. 

Для этого необходимо ввести понятие **вариационно-ковариационной матрицы**



##Вычисление вариационно-ковариационной матрицы
Подобранные параметры (вектор коэффициентов)- это лишь _оценки_ некоторых параметров, описывающих связь между зависимой переменной и предиктором в генеральной совокупности.

Варьирование параметров описывает *вриацонно-ковариационная матрица*.

В среде `R`, если модель задана, например, с помощью функции `lm()`, эта матрица вычисляется так

```{r}
vcov(Mod)
```



##Вычисление вариационо-ковариационной матрицы вручную

$$
\textbf{V}(\pmb{\beta}) = s^2[\textbf{X}'\textbf{X}]^{-1}
$$
где

$$
s^2 = \frac{\sum\limits_{\substack{i=1}}^n e_i^2}{n-k}
$$

$\sum\limits_{\substack{i=1}}^n e_i^2$ - сумма квадратов остатков    
$n$ - объем выборки    
$k$ - число параметров в модели    

##Вычисление вариационо-ковариационной матрицы вручную
Вычисляем $\sum\limits_{\substack{i=1}}^n e_i^2$

```{r}


predict_values <- X %*% betas

resid_values <- cars$dist - predict_values

s2 <- sum(resid_values^2)/(length(resid_values) - length(betas))

s2
```

Видели ли мы это число  в `summary(Mod)`?
>- ДА! это квадрат `Residual standard error: 15.4 on 48 degrees of freedom`


##Вычисление вариационо-ковариационной матрицы вручную
Вычисляем вариационно-ковариационную матрицу

$$
\textbf{V}(\pmb{\beta}) = s^2[\textbf{X}'\textbf{X}]^{-1}
$$

```{r}
covbetas <- s2 * solve(t(X) %*% X)
covbetas
```


##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 5. Вычисляем границы доверительных интервалов

```{r}
# Вычисляем стандартные отшибки путем перемножения матриц
  MyData$se <- sqrt(diag(X2 %*% covbetas %*% t(X2)))

# Вычисляем доверительные интервалы
MyData$CiUp  <- MyData$Predicted + 1.96 *MyData$se

MyData$CiLow  <- MyData$Predicted - 1.96 *MyData$se

```

##Применение матричной алгебры для построения графиков регрессионных моделей  {.smaller .columns-2} 

Шаг 6. Строим график

```{r gg-manual, fig.height=5, fig.width=4, echo=FALSE}
ggplot(MyData, aes(x = speed, y = predicted)) + 
  geom_line(aes(x = speed, y = CiUp), 
            linetype = 2, size = 1) + 
  geom_line(aes(x = speed, y = CiLow), 
            linetype = 2, size = 1)+ 
  geom_abline(slope = betas[2], intercept = betas[1]) +
  geom_point(data = cars, aes(x = speed, y = dist)) +
  ylab("dist")
```
```{r gg-manual, fig.height=5, fig.width=4, eval=FALSE}
```



##Сравним результаты 


```{r, echo=FALSE, fig.height=6}
library(gridExtra)
Pl_gg <- ggplot(cars, aes(x = speed, y = dist)) + geom_point() + geom_smooth(method = "lm") 
Pl_hand <-ggplot(MyData, aes(x = speed, y = predicted)) +   geom_line(aes(x = speed, y = CiUp), linetype = 2, size = 0.5) + geom_line(aes(x = speed, y = CiLow), linetype = 2, size = 0.5) + geom_abline(slope = betas[2], intercept = betas[1], color = "blue", size=1) + geom_point(data = cars, aes(x = speed, y = dist)) + ylab("dist")

grid.arrange(Pl_gg, Pl_hand, ncol = 2)

```


# Not The End
![](images/matrix2.jpg)

##Что почитать
* Legendre P., Legendre L. (2012) Numerical ecology. Second english edition. Elsevier, Amsterdam. Глава 2. Matrix algebra: a summary.



