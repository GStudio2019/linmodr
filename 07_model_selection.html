<!DOCTYPE html>
<html>
<head>
  <title>Сравнение линейных моделей</title>

  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <link rel="stylesheet" media="all" href="site_libs/ioslides-13.5.1/fonts/fonts.css">

  <link rel="stylesheet" media="all" href="site_libs/ioslides-13.5.1/theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="site_libs/ioslides-13.5.1/theme/css/phone.css">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Сравнение линейных моделей',
                        subtitle: 'Линейные модели, дисперсионный и регрессионный анализ с использованием R, осень 2015',
                useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: '07_model_selection_files/logo.png',
              },

      // Author information
      presenters: [
            {
        name:  'Марина Варфоломеева, Вадим Хайтов' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }

    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(07_model_selection_files/logo.png) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>

  <link rel="stylesheet" href="my_styles.css" type="text/css" />

</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="07_model_selection_files/logo.png"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class=''><hgroup><h2>Мы рассмотрим</h2></hgroup><article  id="-">

<ul>
<li>Принципы выбора лучшей линейной модели</li>
<li>Сравнение линейных моделей</li>
<li>Сравнение предсказательной силы линейных моделей с использованием кросс-валидации</li>
</ul>

<h3>Вы сможете</h3>

<ul>
<li>Объяснить связь между качеством описания существующих данных и краткостью модели</li>
<li>Объяснить, что такое &quot;переобучение&quot; модели</li>
<li>Рассказать, каким образом происходит кросс-валидация моделей</li>
<li>Протестировать влияние отдельных параметров линейной регрессии при помощи сравнения вложенных моделей</li>
<li>Оценить предсказательную силу модели при помощи k-кратной кросс-валидации</li>
</ul>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Принципы выбора лучшей линейной модели</h2></hgroup><article  id="----">

<p>&quot;Essentially, all models are wrong,<br/>but some are useful&quot;<br/>Georg E. P. Box</p>

</article></slide><slide class=''><hgroup><h2>Переобучение (overfitting)</h2></hgroup><article  id="-overfitting">

<p>Переобучение происходит, когда из-за избыточного усложнения модель, описывает уже не только отношения между переменными, но и случайный шум</p>

<p>При увеличении числа предикторов в модели: - более точное описание данных, по которым подобрана модель - низкая точност предсказаний на новых данных из-за переобучения.</p>

</article></slide><slide class=''><hgroup><h2>Легче всего переобучение проиллюстрировать на примере полиномиальной регрессии</h2></hgroup><article  id="-------">

<p><img src="07_model_selection_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" /> <img src="07_model_selection_files/figure-html/unnamed-chunk-3-1.png" width="960" style="display: block; margin: auto;" /></p>

</article></slide><slide class=''><hgroup><h2>Компромисс при подборе оптимальной модели:<br />точность vs. смещенная оценка</h2></hgroup><article  id="------vs.--">

<h3>Хорошее описание существующих данных</h3>

<p>Если мы включим много переменных, то лучше опишем данные: большая объясненная изменчивость \(R^2\), маленькая остаточная изменчивость \(MS_{error}\)</p>

<p>Но стандартные ошибки параметров будут большие, интерпретация сложная</p>

<h3>Парсимония</h3>

<p>Минимальный набор переменных, который может объяснить существующие данные</p>

<p>Стандартные ошибки параметров будут ниже, интерпретация проще</p>

</article></slide><slide class=''><hgroup><h2>Критерии и методы выбора моделей зависят от задачи</h2></hgroup><article  id="-------">

<h3>Объяснение закономерностей</h3>

<ul>
<li>Нужны точные тесты влияния предикторов: F-тесты или тесты отношения правдоподобий (likelihood-ratio tests)</li>
</ul>

<h3>Описание функциональной зависимости</h3>

<ul>
<li>Нужна точность оценки параметров и парсимония: \(C _p\) Маллоу, &quot;информационные&quot; критерии (АIC, BIC, AICc, QAIC, и т.д.)</li>
</ul>

<h3>Предсказание значений зависимой переменной</h3>

<ul>
<li>Нужна оценка качества модели на данных, которые не использовались для ее первоначальной подгонки (кросс-валидация, бутстреп)</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Дополнительные критерии для сравнения моделей:</h2></hgroup><article  id="----">

<h3>Не позволяйте компьютеру думать за вас!</h3>

<ul>
<li>Диагностические признаки и качество подгонки (остатки, автокорреляция, распределение ошибок, выбросы и проч.)</li>
<li>Другие соображения (разумность, целесообразность модели, простота, ценность выводов)</li>
</ul>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Сравнение линейных моделей</h2></hgroup><article  id="--">

</article></slide><slide class=''><hgroup><h2>Для тестирования гипотез о влиянии фактора можно сравнить модели с этим фактором и без него.</h2></hgroup><article  id="--------------.">

<ul>
<li>Можно сравнивать для тестирования гипотез только вложенные модели. Это справедливо и для F-критерия, и для likelihood-ratio тестов</li>
</ul>

<h3>Вложенные модели (nested models)</h3>

<p>Две модели являются вложенными, если одну из них можно получить из другой путем удаления некоторых предикторов</p>

<h3>Полная модель (full model)</h3>

<p>\(y _i = \beta _0 + \beta _1 x _1 + \beta _2 x _2 + \epsilon _i\)</p>

<h3>Неполные модели (reduced models), вложены в полную, не вложены друг в друга</h3>

<p>\(y _i = \beta _0 + \beta _1 x _1\), \(y _i = \beta _0 + \beta _2 x _2 + \epsilon _i\)</p>

<h3>Нулевая модель (null model), вложена в полную и в неполные</h3>

<p>\(y _i = \beta _0 + \epsilon _i\)</p>

</article></slide><slide class=''><hgroup><h2>Для тренировки запишем вложенные модели для данной полной модели</h2></hgroup><article  id="--------">

<p>(1)\(y _i = \beta _0 + \beta _1 x _1 + \beta _2 x _2 + \beta _3 x _3 + \epsilon _i\)</p>

<div class="columns-2">
<p>Модели:</p>

<ul>
<li>(2)\(y _i = \beta _0 + \beta _1 x _1 + \beta _2 x _2 + \epsilon _i\)</li>
<li>(3)\(y _i = \beta _0 + \beta _1 x _1 + \beta _3 x _3 + \epsilon _i\)</li>
<li>(4)\(y _i = \beta _0 + \beta _2 x _2 + \beta _3 x _3 + \epsilon _i\)</li>
<li>(5)\(y _i = \beta _0 + \beta _1 x _1 + \epsilon _i\)</li>
<li>(6)\(y _i = \beta _0 + \beta _2 x _2 + \epsilon _i\)</li>
<li>(7)\(y _i = \beta _0 + \beta _3 x _3 + \epsilon _i\)</li>
<li>(8)\(y _i = \beta _0 + \epsilon _i\)<br /><br /></li>
</ul>

<p>Вложенность:</p>

<ul>
<li>(2)-(4)- вложены в (1)<br /><br /><br /></li>
<li>(5)-(7)- вложены в (1), при этом</li>
<li>(5)вложена в (1), (2), (3);</li>
<li>(6)вложена в (1), (2), (4);</li>
<li>(7)вложена в (1), (3), (4)<br /><br /></li>
<li>(8)- нулевая модель - вложена во все</li>
</ul></div>

</article></slide><slide class=''><hgroup><h2>Сравнение линейных моделей при помощи F-критерия</h2></hgroup><article  id="-----f-">

<h3>Полная модель</h3>

<p>\(y _i = \beta _0 + \beta _1 x _{i1} + ... + \beta _k x _{ik} + ... + \beta _p x _{ip} + \epsilon _i\)<br/>\(df _{reduced, full} = p\)<br/>\(df _{error, full} = n - p - 1\)</p>

<h3>Уменьшеная модель</h3>

<p>\(y _i = \beta _0 + \beta _1 x _{i1} + ... + \beta _k x _{ik} + \epsilon _i\)<br/>\(df _{reduced, reduced} = k\)<br/>\(df _{error, reduced} = n - k - 1\)</p>

<h3>Частный F-критерий - оценивает выигрыш объясненной дисперсии от включения фактора в модель</h3>

<p>\[F = \frac {(SS _{error,reduced} - SS _{error,full}) / (df _{reduced, full} - df _{reduced, reduced})} {(SS _{error, full})/ df _{error, full}}\]</p>

</article></slide><slide class=''><hgroup><h2>Сравнение линейных моделей при помощи частного F-критерия</h2></hgroup><article  id="------f-">

<p>Модели обязательно должны быть вложенными!</p>

<h3>Обратный пошаговый алгоритм (backward selection)</h3>

<ol>
<li><p>Строим модели без каждого из предикторов</p></li>
<li><p>Тестируем их отличие от родительской модели</p></li>
<li><p>Переменные, удаление которых <strong>не ухудшает</strong> модель, удаляем. Подбираем новую модель.</p></li>
</ol>

<p>Повторяем 1-3 до тех пор, пока что-то удаляется.</p>

</article></slide><slide class=''><hgroup><h2>Пример: птицы в лесах Австралии</h2></hgroup><article  id="----">

<p>От каких характеристик лесного участка зависит обилие птиц в лесах юго-западной Виктории, Австралия (Loyn, 1987)</p>

<p>Переменных много, мы хотим из них выбрать <strong>оптимальный небольшой</strong> набор.</p>

<div class="columns-2">
<p>56 лесных участков:</p>

<ul>
<li>ABUND - обилие птиц</li>
<li>AREA - площадь участка</li>
<li>YRISOL - год изоляции участка</li>
<li>DIST - расстояние до ближайшего леса</li>
<li>LDIST - расстояние до ближайшего большого леса</li>
<li>GRAZE - пастбищная нагрузка (1-5)</li>
<li>ALT - высота над уровнем моря</li>
</ul>

<p><img src='images/vict_m.jpg' title=''/> <small>Mystic Forest - Warburton, Victoria by ¡kuba! on flickr</small></p></div>

</article></slide><slide class=''><hgroup><h2>Вспомним, что мы знаем про эту модель с прошлого раза</h2></hgroup><article  id="---------">

<pre class = 'prettyprint lang-r'>birds &lt;- read.csv(&quot;data/loyn.csv&quot;)
M &lt;- lm(ABUND ~ ., data = birds)
library(car)
vif(M) # есть колинеарные предикторы</pre>

<pre >##   AREA YRISOL   DIST  LDIST  GRAZE    ALT 
##   1.34   1.84   1.23   1.26   2.31   1.57</pre>

<pre class = 'prettyprint lang-r'># GRAZE - избыточный предиктор, удаляем
M1 &lt;- update(M, .~. - GRAZE)
vif(M1)</pre>

<pre >##   AREA YRISOL   DIST  LDIST    ALT 
##   1.25   1.10   1.16   1.24   1.43</pre>

</article></slide><slide class=''><hgroup><h2>.</h2></hgroup><article  id="section">

<p>Незначимо влияние AREA, DIST, LDIST</p>

<pre class = 'prettyprint lang-r'>summary(M1)</pre>

<pre >## 
## Call:
## lm(formula = ABUND ~ AREA + YRISOL + DIST + LDIST + ALT, data = birds)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.636  -5.211  -0.277   4.735  22.963 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -344.79073   91.61744   -3.76  0.00044 ***
## AREA           0.00459    0.00488    0.94  0.35132    
## YRISOL         0.17928    0.04760    3.77  0.00044 ***
## DIST           0.00772    0.00571    1.35  0.18233    
## LDIST          0.00192    0.00141    1.36  0.17978    
## ALT            0.07638    0.03195    2.39  0.02062 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.61 on 50 degrees of freedom
## Multiple R-squared:  0.415,  Adjusted R-squared:  0.357 
## F-statistic:  7.1 on 5 and 50 DF,  p-value: 0.000044</pre>

</article></slide><slide class=''><hgroup><h2>Частный F-критерий, 1 способ: <code>anova(модель_1, модель_2)</code></h2></hgroup><article  id="-f--1--anova_1-_2">

<p>Вручную выполняем все действия</p>

<pre class = 'prettyprint lang-r'>M2 &lt;- update(M1, . ~ . - AREA)
anova(M1, M2)</pre>

<pre >## Analysis of Variance Table
## 
## Model 1: ABUND ~ AREA + YRISOL + DIST + LDIST + ALT
## Model 2: ABUND ~ YRISOL + DIST + LDIST + ALT
##   Res.Df  RSS Df Sum of Sq    F Pr(&gt;F)
## 1     50 3707                         
## 2     51 3772 -1     -65.6 0.89   0.35</pre>

</article></slide><slide class=''><hgroup><h2>Частный F-критерий, 2 способ: <code>drop1()</code></h2></hgroup><article  id="-f--2--drop1">

<p>Вручную тестировать каждый предиктор с помощью <code>anova()</code> слишком долго. Можно протестировать все за один раз при помощи <code>drop1()</code></p>

<pre class = 'prettyprint lang-r'>drop1(M1, test = &quot;F&quot;)</pre>

<pre >## Single term deletions
## 
## Model:
## ABUND ~ AREA + YRISOL + DIST + LDIST + ALT
##        Df Sum of Sq  RSS AIC F value  Pr(&gt;F)    
## &lt;none&gt;              3707 247                    
## AREA    1        66 3772 246    0.89 0.35132    
## YRISOL  1      1052 4759 259   14.19 0.00044 ***
## DIST    1       136 3842 247    1.83 0.18233    
## LDIST   1       137 3844 247    1.85 0.17978    
## ALT     1       424 4130 251    5.72 0.02062 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

<pre class = 'prettyprint lang-r'># Нужно убрать AREA</pre>

</article></slide><slide class=''><hgroup><h2>.</h2></hgroup><article  id="section-1">

<pre class = 'prettyprint lang-r'># Убрали AREA
M2 &lt;- update(M1, . ~ . - AREA)
drop1(M2, test = &quot;F&quot;)</pre>

<pre >## Single term deletions
## 
## Model:
## ABUND ~ YRISOL + DIST + LDIST + ALT
##        Df Sum of Sq  RSS AIC F value  Pr(&gt;F)    
## &lt;none&gt;              3772 246                    
## YRISOL  1      1004 4776 257   13.57 0.00056 ***
## DIST    1       166 3938 246    2.24 0.14027    
## LDIST   1       165 3937 246    2.23 0.14150    
## ALT     1       719 4491 254    9.72 0.00300 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

<pre class = 'prettyprint lang-r'># Нужно убрать LDIST</pre>

</article></slide><slide class=''><hgroup><h2>.</h2></hgroup><article  id="section-2">

<pre class = 'prettyprint lang-r'># Убрали LDIST
M3 &lt;- update(M2, . ~ . - LDIST)
drop1(M3, test = &quot;F&quot;)</pre>

<pre >## Single term deletions
## 
## Model:
## ABUND ~ YRISOL + DIST + ALT
##        Df Sum of Sq  RSS AIC F value Pr(&gt;F)    
## &lt;none&gt;              3937 246                   
## YRISOL  1       959 4896 256   12.67 0.0008 ***
## DIST    1       311 4248 248    4.11 0.0478 *  
## ALT     1       589 4526 252    7.78 0.0074 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

<pre class = 'prettyprint lang-r'># Больше ничего убрать не получается</pre>

</article></slide><slide class=''><hgroup><h2>Итоговая модель</h2></hgroup><article  id="-">

<pre class = 'prettyprint lang-r'>summary(M3)</pre>

<pre >## 
## Call:
## lm(formula = ABUND ~ YRISOL + DIST + ALT, data = birds)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -16.60  -5.75   0.57   5.08  23.72 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -325.25283   91.81925   -3.54  0.00085 ***
## YRISOL         0.16961    0.04766    3.56  0.00080 ***
## DIST           0.01103    0.00544    2.03  0.04784 *  
## ALT            0.07807    0.02800    2.79  0.00738 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.7 on 52 degrees of freedom
## Multiple R-squared:  0.379,  Adjusted R-squared:  0.343 
## F-statistic: 10.6 on 3 and 52 DF,  p-value: 0.0000156</pre>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Тесты отношения правдоподобий</h2></hgroup><article  id="--">

</article></slide><slide class=''><hgroup><h2>Правдоподобие</h2></hgroup><article >

<p>Помимо доли объясненной дисперсии, у каждой модели можно посчитать ее правдоподобие (likelihood) - соотверствие полученных данных нашей модели</p>

<p>Чтобы измерить правдоподобие нам нужно оценить вероятность получения набора данных при справедливости нашей модели.</p>

<p>Мы оцениваем это как произведение вероятностей получения каждой из точек данных</p>

<p>\(L(x_1, ..., x_n) = \Pi^n _{i = 1}f(x_i; \theta)\)</p>

<p>где \(f(x; \theta)\) - функция плотности распределения с параметрами \(\theta\)</p>

</article></slide><slide class=''><hgroup><h2>Выводим формулу правдоподобия для линейной модели с нормальным распределением ошибок</h2></hgroup><article  id="---------">

<p>Пусть в нашей модели остатки нормально распределены (\(\epsilon_i \sim N(0, \sigma^2)\)) и их значения независимы друг от друга:</p>

<p>\(N(\epsilon_i; 0, \sigma^2) = \frac {1} { \sqrt {2\pi\sigma^2} } exp (-\frac {1} {2 \sigma^2} \epsilon^2)\)</p>

<p>Тогда можно описать вероятность получения нашего набора данных при помощи функции правдоподобия (likelihood), как произведение вероятностей:</p>

<p>\(L = \Pi^n _{n = 1} N(\epsilon, \sigma^2) = (\frac {1} {2\pi\sigma^2})^{n/2} exp(- \frac {1} {2\sigma^2} \sum \epsilon^2_i)\)</p>

<p>\(\epsilon = y_i - \hat y_i\)</p>

<p>В случае регрессии от одной переменной (для простоты), поскольку \(\hat y_i = b_0 + b_1 x\), то правдоподобие - это функция от \(b_0\), \(b_1\) и \(\sigma\).</p>

</article></slide><slide class=''><hgroup><h2>Логарифм правдоподобия</h2></hgroup><article  id="-">

<p>Часто вычислительно проще работать с логарифмами правдоподобий (loglikelihood)</p>

<p>\(logLik (\beta, \sigma) = - \frac{n}{2} ln(2\pi) - \frac{n}{2} ln(\sigma^2) - \frac{1}{2\sigma^2}(\sum \epsilon^2_i)\)</p>

<h3>Применение:</h3>

<ul>
<li><p>Метод максимального правдоподобия используется для подбора параметров регрессии (берут частные производные, приравнивают к нулю, решают уравнения)</p></li>
<li><p>Правдоподобия разных моделей, подобранных на одинаковом наборе данных можно оценить и сравнивать друг с другом. Чем больше \(logLik\), тем лучше модель.</p></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Тест отношения правдоподобий (Likelihood Ratio Test)</h2></hgroup><article  id="---likelihood-ratio-test">

<p>Тест отношения правдоподобий позволяет определить какая модель более правдоподобна с учетом данных.</p>

<p>\(LRT = 2ln(L_1/L_2) = 2(logL_1 - logL_2)\)</p>

<ul>
<li>\(L_1\), \(L_2\) - правдоподобия полной и уменьшеной модели</li>
<li>\(logL_1\), \(logL_2\) - логарифмы правдоподобий</li>
</ul>

<p>Чем больше \(logLik\), тем лучше модель.</p>

<p>Разница логарифмов правдоподобий имеет распределение \(\chi^2\) с числом степеней свободы \(df = df_2 - df_1\)</p>

</article></slide><slide class=''><hgroup><h2>Делаем тест отношения правдоподобий</h2></hgroup><article  id="---">

<p>Переподберем нашу полную модель при помощи метода максимального правдоподобия</p>

<pre class = 'prettyprint lang-r'>GLM1 &lt;- glm(ABUND ~ . - GRAZE, data = birds)</pre>

<p>Тест отношения правдоподобий можно сделать с помощью тех же функций, что и частный F-критерий:</p>

<ul>
<li>по-одному <code>anova(mod1, mod2, test = &quot;Chisq&quot;)</code></li>
<li>все сразу <code>drop1(mod1, test = &quot;Chisq&quot;)</code></li>
</ul>

<h3>Задание: Подберите оптимальную модель при помощи тестов отношения правдоподобий</h3>

</article></slide><slide class=''><hgroup><h2>Решение (шаг 1)</h2></hgroup><article  id="--1">

<pre class = 'prettyprint lang-r'>drop1(GLM1, test = &quot;Chisq&quot;)</pre>

<pre >## Single term deletions
## 
## Model:
## ABUND ~ (AREA + YRISOL + DIST + LDIST + GRAZE + ALT) - GRAZE
##        Df Deviance AIC scaled dev. Pr(&gt;Chi)    
## &lt;none&gt;        3707 408                         
## AREA    1     3772 407        0.98  0.32154    
## YRISOL  1     4759 420       13.99  0.00018 ***
## DIST    1     3842 408        2.01  0.15607    
## LDIST   1     3844 408        2.04  0.15366    
## ALT     1     4130 412        6.06  0.01382 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

<pre class = 'prettyprint lang-r'># Нужно убрать AREA</pre>

</article></slide><slide class=''><hgroup><h2>Решение (шаг 2)</h2></hgroup><article  id="--2">

<pre class = 'prettyprint lang-r'># Убираем AREA
GLM2 &lt;- update(GLM1, . ~ . - AREA)
drop1(GLM2, test = &quot;Chisq&quot;)</pre>

<pre >## Single term deletions
## 
## Model:
## ABUND ~ YRISOL + DIST + LDIST + ALT
##        Df Deviance AIC scaled dev. Pr(&gt;Chi)    
## &lt;none&gt;        3772 407                         
## YRISOL  1     4776 418       13.21  0.00028 ***
## DIST    1     3938 407        2.41  0.12043    
## LDIST   1     3937 407        2.40  0.12159    
## ALT     1     4491 414        9.77  0.00178 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

<pre class = 'prettyprint lang-r'># Нужно убрать LDIST</pre>

</article></slide><slide class=''><hgroup><h2>Решение (шаг 3)</h2></hgroup><article  id="--3">

<pre class = 'prettyprint lang-r'># Убираем LDIST
GLM3 &lt;- update(GLM2, . ~ . - LDIST)
drop1(GLM3, test = &quot;Chisq&quot;)</pre>

<pre >## Single term deletions
## 
## Model:
## ABUND ~ YRISOL + DIST + ALT
##        Df Deviance AIC scaled dev. Pr(&gt;Chi)    
## &lt;none&gt;        3937 407                         
## YRISOL  1     4896 417       12.21  0.00048 ***
## DIST    1     4248 409        4.26  0.03908 *  
## ALT     1     4526 413        7.80  0.00521 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</pre>

<pre class = 'prettyprint lang-r'># Больше ничего убрать не получается</pre>

</article></slide><slide class=''><hgroup><h2>Решение (шаг 4)</h2></hgroup><article  id="--4">

<pre class = 'prettyprint lang-r'>summary(GLM3)</pre>

<pre >## 
## Call:
## glm(formula = ABUND ~ YRISOL + DIST + ALT, data = birds)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -16.60   -5.75    0.57    5.08   23.72  
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -325.25283   91.81925   -3.54  0.00085 ***
## YRISOL         0.16961    0.04766    3.56  0.00080 ***
## DIST           0.01103    0.00544    2.03  0.04784 *  
## ALT            0.07807    0.02800    2.79  0.00738 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 75.7)
## 
##     Null deviance: 6337.9  on 55  degrees of freedom
## Residual deviance: 3937.3  on 52  degrees of freedom
## AIC: 407.1
## 
## Number of Fisher Scoring iterations: 2</pre>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Информационные критерии</h2></hgroup><article  id="-">

</article></slide><slide class=''><hgroup><h2>AIC - Информационный критерий Акаике (Akaike Information Criterion)</h2></hgroup><article  id="aic------akaike-information-criterion">

<p>\(AIC = -2 logLik + 2p\)</p>

<ul>
<li>\(logLik\) - логарифм правдоподобия для модели</li>
<li>\(2p\) - штраф за введение в модель p параметров</li>
</ul>

<p>Чем меньше AIC - тем лучше модель</p>

</article></slide><slide class=''><hgroup><h2>Другие информационные критерии</h2></hgroup><article  id="--">

<table class = 'rmdtable'>
<col width="9%" />
<col width="9%" />
<col width="9%" />
<tr class="header">
<th align="left">Критерий</th>
<th align="left">Название</th>
<th align="left">Формула</th>
</tr>
<tr class="odd">
<td align="left">AIC</td>
<td align="left">Информационный критерий Акаике</td>
<td align="left">\(AIC = -2 logLik + 2p\)</td>
</tr>
<tr class="even">
<td align="left">BIC</td>
<td align="left">Баесовский информационный критерий</td>
<td align="left">\(BIC = -2 logLik + p \cdot ln(n)\)</td>
</tr>
<tr class="odd">
<td align="left">AICc</td>
<td align="left">Информационный критерий Акаике с коррекцией для малых выборок (малых относительно числа параметров: \(n/p &lt; 40\), Burnham, Anderson, 2004)</td>
<td align="left">\(AIC_c = -2 logLik + 2p + \frac{2p(p + 1)}{n - p - 1}\)</td>
</tr>
<tr class="even">
<td align="left">QAIC</td>
<td align="left">Информационный критерий Акаике с использованием квазиправдоподобия - для данных со сверхдисперсией (позже)</td>
<td align="left"></td>
</tr>
</table>

<ul>
<li>\(logLik\) - логарифм правдоподобия для модели</li>
<li>\(p\) - число параметров</li>
<li>\(n\) - число наблюдений</li>
</ul>

<h3>Рассчитаем AIC для наших моделей</h3>

<pre class = 'prettyprint lang-r'>AIC(GLM1, GLM2, GLM3)</pre>

<pre >##      df AIC
## GLM1  7 408
## GLM2  6 407
## GLM3  5 407</pre>

<pre class = 'prettyprint lang-r'># По AIC лучшая модель GLM2</pre>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Сравнение предсказательной силы моделей</h2></hgroup><article  id="---">

</article></slide><slide class=''><hgroup><h2>Кросс-валидация</h2></hgroup><article  id="-">

<p>Если оценивать качество модели по тем же данным, по которым она была подобрана, оценки будут завышенными из-за переобучения. Кросс-валидация решает эту проблему.</p>

<p>Делим данные <strong>случайным образом</strong> на <strong>тренировочное и тестовое подмножества</strong>, обычно в пропорции 60:40, 70:30 или 80:20</p>

<p><img src="07_model_selection_files/figure-html/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>

<div class="columns-2">
<h3>Тренировочные данные</h3>

<p>Используются для подбора модели (для обучения)</p>

<p>Чтобы модель была хорошей, тренировочных данных <strong>должно быть много</strong></p>

<h3>Тестовые данные</h3>

<p>Используются для оценки качества модели</p>

<p>Чтобы надежно оценить качество модели, тестовых данных <strong>тоже должно быть много</strong></p></div>

</article></slide><slide class=''><hgroup><h2>K-кратная кросс-валидация (k-fold cross-validation)</h2></hgroup><article  id="k----k-fold-cross-validation">

<p>Делим данные <strong>случайным образом</strong> на \(k\) частей<br/>\(k - 1\) часть используется для обучения, на \(k\)-й части тестируется качество предсказаний модели<br/>Процедура повторяется \(k\) раз</p>

<p><img src="07_model_selection_files/figure-html/unnamed-chunk-18-1.png" width="672" style="display: block; margin: auto;" /></p>

<p>\(k\)-кратная кросс-валидация лучше обычной, особенно, если данных немного</p>

</article></slide><slide class=''><hgroup><h2>Один из способов оценить качество предсказаний это RMSE - стандартная ошибка предсказания</h2></hgroup><article  id="-------rmse-----">

<p>\[RMSE = \sqrt { \frac {\sum{({y _{i}} - \hat y _{i})^2}} {n} }\]</p>

<p>Это параметр, который определяет ширину доверительных интервалов предсказаний. Чем меньше \(RMSE\), тем точнее предсказания и тем лучше модель.</p>

<ul>
<li>Нет жестких границ для \(RMSE\) &quot;хорошей&quot; модели, это относительная величина.</li>
<li>\(RMSE\) разных моделей можно сравнивать, только если они в одинаковых единицах (исходные данные моделей преобразованы одинаково, зависимая переменная в одних и тех же единицах)</li>
<li>Чувствительна к выборосам (альтернатива - \(MAE\) - средний модуль ошибок)</li>
<li>Бывает, что критерии противоречат друг другу, тогда учитываем другие соображения, например, простоту и интерпретируемость. Лучше меньше параметров.</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Этапы сравнения моделей с использованием кросс-валидации</h2></hgroup><article  id="------">

<ul>
<li><p>Делим данные на тренировочное и тестовое подмножества</p></li>
<li>Для каждой из моделей-кандидатов повторяем следующие шаги</li>
<li>Подбираем на тренировочном подмножестве модель-кандидат</li>
<li>Используя тестовые данные, предсказываем ожидаемые значение \(y\) используя модель-кандидат</li>
<li><p>Рассчитываем \(RMSE\) для модели-кандидата (стандартное отклонение остатков)</p></li>
</ul>

<p>\[RMSE = \sqrt { \frac {\sum{({y _{i}} - \hat y _{i})^2}} {n} }\]</p>

<ul>
<li>Сравниваем \(RMSE\) всех моделей кандидатов. Модель, у которой минимальное значение \(RMSE\) - лучшая</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Кросс-валидация для линейных моделей</h2></hgroup><article  id="----">

<p>Пакет <code>caret</code> позволяет подбирать практически любые модели. В нем много способов оценки предсказательной силы моделей.</p>

<pre class = 'prettyprint lang-r'>library(caret)
SEED &lt;- 233
# Кросс-валидация, 5-кратная в д.сл.
train_control &lt;- trainControl(method = &quot;cv&quot;, number = 5)

f1 &lt;- ABUND ~ AREA + YRISOL + DIST + LDIST + ALT
set.seed(SEED)
MCV1 &lt;- train(f1, data = birds, trControl = train_control, method = &quot;lm&quot;)

MCV1$resample # результаты на разных фолдах</pre>

<pre >##    RMSE Rsquared Resample
## 1 10.84   0.0441    Fold1
## 2  7.53   0.6269    Fold2
## 3  8.68   0.3245    Fold3
## 4  7.43   0.6075    Fold4
## 5  9.93   0.1098    Fold5</pre>

<pre class = 'prettyprint lang-r'>MCV1$results # итоговая статистика</pre>

<pre >##   intercept RMSE Rsquared RMSESD RsquaredSD
## 1      TRUE 8.88    0.343   1.49      0.271</pre>

</article></slide><slide class=''><hgroup><h2>Задание:</h2></hgroup><article >

<p>Рассчитайте при помощи кросс-валидации \(RMSE\) для моделей</p>

<pre class = 'prettyprint lang-r'>f2 &lt;- ABUND ~ YRISOL + DIST + LDIST + ALT
f3 &lt;- ABUND ~ YRISOL + DIST + ALT</pre>

</article></slide><slide class=''><hgroup><h2>Решение</h2></hgroup><article >

<pre class = 'prettyprint lang-r'>f2 &lt;- ABUND ~ YRISOL + DIST + LDIST + ALT
set.seed(SEED)
MCV2 &lt;- train(f2, data = birds, trControl = train_control, method = &quot;lm&quot;)

f3 &lt;- ABUND ~ YRISOL + DIST + ALT
set.seed(SEED)
MCV3 &lt;- train(f3, data = birds, trControl = train_control, method = &quot;lm&quot;)

# Сравниваем три модели
MCV1$results</pre>

<pre >##   intercept RMSE Rsquared RMSESD RsquaredSD
## 1      TRUE 8.88    0.343   1.49      0.271</pre>

<pre class = 'prettyprint lang-r'>MCV2$results</pre>

<pre >##   intercept RMSE Rsquared RMSESD RsquaredSD
## 1      TRUE 8.84    0.346   1.52      0.273</pre>

<pre class = 'prettyprint lang-r'>MCV3$results</pre>

<pre >##   intercept RMSE Rsquared RMSESD RsquaredSD
## 1      TRUE 8.91     0.32   1.51      0.249</pre>

<pre class = 'prettyprint lang-r'># самая маленькая RMSE при 5-кратной кросс-валидации</pre>

</article></slide><slide class=''><hgroup><h2>График значений \(RMSE\) и \(R^2\) для каждого фолда в кросс-валидации трех наших моделей</h2></hgroup><article  id="--rmse--r2---------">

<p>Каждая линия - фолд</p>

<p><img src="07_model_selection_files/figure-html/unnamed-chunk-22-1.png" width="960" style="display: block; margin: auto;" /></p>

</article></slide><slide class=''><hgroup><h2>Можем повторить всю процедуру оценки качества модели другим методом - бутстрепом</h2></hgroup><article  id="-----------">

<pre class = 'prettyprint lang-r'>train_control &lt;- trainControl(method = &quot;boot&quot;, number = 100)

MCV1b &lt;- train(f1, data = birds, trControl = train_control, method = &quot;lm&quot;)
MCV2b &lt;- train(f2, data = birds, trControl = train_control, method = &quot;lm&quot;)
MCV3b &lt;- train(f3, data = birds, trControl = train_control, method = &quot;lm&quot;)

# Сравниваем три модели
MCV1b$results</pre>

<pre >##   intercept RMSE Rsquared RMSESD RsquaredSD
## 1      TRUE 18.9    0.286   25.8       0.14</pre>

<pre class = 'prettyprint lang-r'>MCV2b$results</pre>

<pre >##   intercept RMSE Rsquared RMSESD RsquaredSD
## 1      TRUE 9.16    0.341   1.07      0.147</pre>

<pre class = 'prettyprint lang-r'>MCV3b$results # Лучшая</pre>

<pre >##   intercept RMSE Rsquared RMSESD RsquaredSD
## 1      TRUE 9.18    0.332    1.4      0.154</pre>

</article></slide><slide class=''><hgroup><h2>График значений \(RMSE\) и \(R^2\) для каждой выборки при проверке трех наших моделей при помощи бутстрепа</h2></hgroup><article  id="--rmse--r2-----------">

<p>Каждая линия - отдельная выборка</p>

<p><img src="07_model_selection_files/figure-html/unnamed-chunk-24-1.png" width="960" style="display: block; margin: auto;" /></p>

</article></slide><slide class=''><hgroup><h2>Takehome messages</h2></hgroup><article  id="takehome-messages">

<ul>
<li>Модели, которые качественно описывают существующие данные включают много параметров, но предсказания с их помощью менее точны из-за переобучения</li>
<li>Для выбора оптимальной модели используются разные критерии в зависимости от задачи</li>
<li>Сравнивая вложенные модели можно отбраковать переменные, включение которых в модель не улучшает ее</li>
<li>Оценить предсказательную силу модели на <strong>новых данных</strong> можно при помощи кросс-валидации или бутстрепа, сравнив ошибки предсказаний</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Дополнительные ресурсы</h2></hgroup><article  id="-">

<p>James, G., Witten, D., Hastie, T., Tibshirani, R., 2013. An introduction to statistical learning. Springer. - 2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability - 2.2.2 The Bias-Variance Trade-Off - 3.2.2 Some Important Questions</p>

<p>Kuhn, M., Johnson, K., 2013. Applied Predictive Modeling. Springer. - 1.1 Prediction Versus Interpretation - 1.2 Key Ingredients of Predictive Models - 4 Over-Fitting and Model Tuning - 5 Measuring Performance in Regression Models</p>

<p>Quinn, G.G.P., Keough, M.J., 2002. Experimental design and data analysis for biologists. Cambridge University Press. - 6.1.15 Finding the “best” regression model - 6.1.16 Hierarchical partitioning</p></article></slide>


  <slide class="backdrop"></slide>

</slides>

<script src="site_libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
<script src="site_libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
<script src="site_libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
<script src="site_libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
<script src="site_libs/ioslides-13.5.1/js/hammer.js"></script>
<script src="site_libs/ioslides-13.5.1/js/slide-controller.js"></script>
<script src="site_libs/ioslides-13.5.1/js/slide-deck.js"></script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
