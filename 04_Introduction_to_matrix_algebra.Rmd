---
title: "Краткое введение в мир матричной алгебры"
subtitle: "Линейные модели..."
author: "Вадим Хайтов, Марина Варфоломеева"
output:
  ioslides_presentation:
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
    widescreen: yes
---

## Вы сможете
- Объяснить что такое матрицы и какие бывают их основные разновидности
- Выполнить базовые операции с матрицами с использованием функций R
- Применить в среде R методы матричной алгебры для решения простейших задач




```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

# Зачем нужны матрицы?

##Матричные объекты
- Есть много типов объектов, для которых такое выражение оказывается наиболее естественным (изображения, описания многомерных объектов и т.д.)
- В матрицах, как и в обычных числах, скрыта информация, которую можно извлекать и преобразовывать по определенным правилам


## Структура матриц

$$\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1c} \\
a_{21} & a_{22} & \cdots & a_{2c} \\    
\vdots & \vdots & \ddots & \vdots \\
a_{r1} & a_{r2} & \cdots & a_{rc}
\end{pmatrix}
    $$

Размер (порядок) матрицы $r \times c$ 

## Разновидности матриц 

Вектор-строка (row matrix)

$$ 
\textbf {A} =
\begin{pmatrix}
1 & 2 & 3 
\end{pmatrix}
$$


Вектор-столбец (column matrix)

$$ \textbf {B} =
\begin{pmatrix}
1 \\
4 \\    
7 \\
10 
\end{pmatrix}
$$

## Разновидности матриц 

Прямоугольные матрицы (rectangular matrices)

$$ \textbf {C} =
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\    
7 & 8 & 9 \\
10 & 11 & 12 
\end{pmatrix}
$$


$$ \textbf {D} =
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6     
\end{pmatrix}
$$

В таком виде обычно представляются исходные данные

##Квадратные матрицы (square matrices)

Это наиболее "операбельные" матрицы

$$ \textbf {E} =
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\    
7 & 8 & 9 
\end{pmatrix}
$$

Диагональные матрицы (diagonal matrix)

$$ \textbf {F} =
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 5 & 0 & 0 \\    
0 & 0 & 9 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix}
$$


##Квадратные матрицы (square matrices)

Треугольные матрицы (triangular matrices)
$$ \textbf {H} =
\begin{pmatrix}
1 & 2 & 3 & 4 \\
0 & 5 & 6 & 7 \\    
0 & 0 & 9 & 10 \\
0 & 0 & 0 & 1
\end{pmatrix}
$$

или

$$ \textbf {H} =
\begin{pmatrix}
1 & 0 & 0 & 0 \\
3 & 5 & 0 & 0 \\    
4 & 7 & 9 & 0 \\
5 & 8 & 10 & 11
\end{pmatrix}
$$

##Квадратные матрицы (square matrices)

Единичная матрица (identity matrix)
$$ 
\textbf {I} =
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\    
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix}
$$



Единичная матрица (обозначение $\textbf{I}$) занимают особое место в матричной алгебре.   
Она выполняет ту же роль, которую выполняет единица в обычной алгебре. 



##Особенность квадратных матриц

Для квадратных матриц могут быть найдены (но не обязательно существуют) некоторые важные для матричной алгебры показатели: *определитель*, *инверсия*, *собственные значения* и *собственные вектора*




##Задание
Создайте с помощью R следующие матрицы

```{r, echo=FALSE}
matrix(1:12, ncol = 3)

```


```{r, echo=FALSE, purl = FALSE}
diag(rep(1,5))

```

#Операции с матрицами

##Транспонирование матриц

```{r}
A <- matrix(1:12, ncol = 3)
A

```

Транспонированная матрица $\textbf{A}$
```{r}
B <- t(A)
B

```

##Сложение матриц
```{r, purl = FALSE}
A + 4

```

```{r, purl = FALSE}
A + A

```

Но! Нельзя складывать матрицы разных размеров
```{r, eval=FALSE, purl = FALSE}
A + B

```

##Биологическое приложение
Предположим, что мы подсчитывали двумя разными методами крупных и мелких животных  трех  видов в одних и тех же пробах

```{r, echo = FALSE, purl = T}
Large <- data.frame(Sp1 = round(rnorm(5, 10, 2)), Sp2 = round(rnorm(5, 10, 3)), Sp3 = round(rnorm(5, 10, 2))) 

rownames(Large) <- c("Sample1", "Sample2", "Sample3", "Sample4", "Sample5" )

Small <- data.frame(Sp1 = round(rnorm(5, 50, 5)), Sp2 = round(rnorm(5, 50, 5)), Sp3 = round(rnorm(5, 50, 5))) 

rownames(Small) <- c("Sample1", "Sample2", "Sample3", "Sample4", "Sample5" )

```

```{r, echo=FALSE, purl = FALSE}
Large
Small

```

##Биологическое приложение

Общее обилие 
```{r, purl = T}
Large + Small

```


##Простое умножение 
Умножение на число
```{r, purl = FALSE}
A * 4

```

Простое умножение матрицы на вектор возможно только если число элементов в векторе равно числу строк в матрице

```{r, purl = FALSE}
A * c(10, 11, 12, 13)
```

Все элементы первой строки матрицы умножаются на первый элемент вектора, все элементы второй строки на второй элемент вектора и т.д.  


##Биологическое применение
Допустим, учет организмов в части описаний проходил не на всей выборке, а лишь в ее части.
```{r, purl = T}
Rpocessed_portion <- c(1, 1, 1/2, 1/3, 1/4)
Processed_Factor <- 1/Rpocessed_portion

```

```{r, purl = T}
Small * Processed_Factor

```


##  Скалярное произведение векторов   
Допустимо только для векторов одинаковой размерности

$$
\textbf{a} \bullet \textbf{b} =  
\begin{pmatrix}
a_1 \\
a_3 \\    
a_4 \\
a_5 \\
a_6 \\
a_7
\end{pmatrix}
\times
\begin{pmatrix}
b_1 &
b_3 &    
b_4 &
b_5 &
b_6 &
b_7
\end{pmatrix}
= x
$$

Результат этой операции - число (скаляр)


##Биологическое применение
Сколько особей родится в популяции, если мы знаем репродуктивные характеристики всех возрастных групп?
$$
\begin{pmatrix}
N_1 \\
N_3 \\    
N_4 \\
N_5 \\
N_6 \\
N_7
\end{pmatrix}
\times
\begin{pmatrix}
F_1 & F_2 & F_3 & F_4 & F_5 & F_6 & F_7
\end{pmatrix}
$$

```{r}
N <- c(20, 40, 32, 45, 80, 50, 10)
Fert <- c( 0,  0,   1,   2,   2,   0,   0)

t(N) %*% (Fert)
```


##Умножение матриц
Умножать можно только в том случае, если число строк одной матрицы равно числу столбцов другой матрицы

```{r}
A %*% B
```

```{r}
A %*% t(A)

```


НО! Нельзя произвести такое умножение
```{r, eval=FALSE}
A %*% A

```




##Биологическое применение
Простейший пример использования умножения матриц - построение модели динамики демографической структуры популяции
Для вычислений необходим начальный *демографический вектор* и *матрица Лесли*

$$
\begin{pmatrix}
F_1 & F_2 & F_3 & F_4 & F_5 & F_6 & F_7 \\
P_{1-2}& 0 & 0 & 0 & 0 & 0 & 0 \\    
0 & P_{2-3} & 0 & 0 & 0 & 0 & 0 \\    
0 & 0 & P_{3-4} & 0 & 0 & 0 & 0 \\    
0 & 0 & 0 & P_{4-5} & 0 & 0 & 0 \\    
0 & 0 & 0 & 0 & P_{5-6} & 0 & 0 \\    
0 & 0 & 0 & 0 & 0 & P_{6-7} & 0     
\end{pmatrix}
\times
\begin{pmatrix}
N1_t \\
N3_t \\    
N4_t \\
N5_t \\
N6_t \\
N7_t
\end{pmatrix}
=
\begin{pmatrix}
N1_{t+1} \\
N3_{t+1} \\    
N4_{t+1} \\
N5_{t+1} \\
N6_{t+1} \\
N7_{t+1}
\end{pmatrix}
$$

##Простейшая демографическая модель


```{r, echo=FALSE}
T1 <- c(20, 40, 32, 45, 80, 50, 10)
Age <- c("0", "1-10", "11-20", "21-35", "36-45", "46-55", "56-65")
Pop <- data.frame(Age, T1)

```


Демографический вектор в момент времени $t$ 
```{r, echo=FALSE}
Pop
```

Матрица Лесли
```{r, echo=FALSE}
Lesl <- matrix(
c( 0,  0,   1,   2,   2,   0,   0,
  0.6, 0,   0,   0,   0,   0,   0,
   0,  0.7, 0,   0,   0,   0,   0, 
   0,  0,   0.8, 0,   0,   0,   0,
   0,  0,   0,   0.7, 0,   0,   0,
   0,  0,   0,   0,   0.6, 0,   0,
   0, 0,    0,   0,   0,  0.2, 0  ),
byrow = T, 
ncol = 7)
Lesl

```

## Демографическая струкутра в момент времени $t+1$ 


```{r}
Pop$T2 <- as.vector( Lesl %*% (Pop$T1 ))
Pop$T3 <- as.vector( Lesl %*% (Pop$T2 ))
Pop$T4 <- as.vector( Lesl %*% (Pop$T3 ))
Pop$T5 <- as.vector( Lesl %*% (Pop$T4 ))
Pop$T6 <- as.vector( Lesl %*% (Pop$T5 ))
Pop$T7 <- as.vector( Lesl %*% (Pop$T6 ))
Pop$T8 <- as.vector( Lesl %*% (Pop$T7 ))
Pop$T9 <- as.vector( Lesl %*% (Pop$T8 ))
Pop$T10 <- as.vector( Lesl %*% (Pop$T9 ))
```

## Демографическая струкутра в момент времени $t+1$ 

```{r, echo=FALSE, message=FALSE, fig.width=6, fig.height=6}
library(ggplot2)
library(reshape)
Pop2 <- melt(Pop)
ggplot(Pop2, aes(x=Age, y = value)) + geom_bar(stat = "identity") + facet_wrap(~variable, ncol = 2) + labs(x = "Возраст", y = "Число особей")

```

## Вычисление корреляций через произведение матриц
Используем известные нам данные по размеру головного мозга
```{r}
brain <- read.csv("data/IQ_brain.csv", header = TRUE)
br <- brain[complete.cases(brain), -1]
br <- as.matrix(br)
br_scaled <- scale(br) #Стандартизуем значения

cor_matrix <- t(br_scaled) %*% br_scaled / (nrow(br_scaled) - 1) 

cor_matrix
```

##Некоторые свойства произведения матриц
1) Если существует произведение матриц $\textbf{BC}$, то не обязательно существует $\textbf{CB}$

```{r}
B <- matrix(1:24, ncol = 4)
C <- matrix(1:12, ncol = 3)

B %*% C
```

HO! 

```{r, eval=FALSE}

C %*% B
```

Такое произведение невозможно

##Некоторые свойства произведения матриц
2) Всегда существует такое произведение матриц $\textbf{CС'}$ и $\textbf{C'С}$

```{r}
C %*% t(C)
```

```{r}
t(C) %*% C
```


##Некоторые свойства произведения матриц
3) Произведение матриц $\textbf{BC}$ как правило не равно $\textbf{CB}$
```{r}
B <- matrix(1:9, ncol = 3)
C <- matrix(11:19, ncol = 3)

B %*%  C

C %*% B
```

##Некоторые свойства произведения матриц
4)  $[\textbf{BC}]' = \textbf{C}'\textbf{B}'$
```{r}
t(B %*% C)
```

```{r}
t(C) %*% t(B)
```

##Некоторые свойства произведения матриц
5)  Произведение $\textbf{BB'}$ и $\textbf{B'B}$ всегда дает симметричную матрицу 

```{r}
B %*% t(B)
```

```{r}
t(B) %*% B

```



##Определитель матрицы
Определитель матрицы - это некоторое число.   

По значению этого числа можно *определить* есть ли у матрицы некоторые свойства (например, обратима ли матрица).  

Определитель бывает только у квадратных матриц.   

Матрицы, имеющие определитель равный нулю, называются *сингулярными* матрицами.  

```{r}
det(B)
```



```{r}
BB <- t(B) %*% B
det(BB)
```





##Обращение (инверсия) матриц 

В матричной алгебре нет процедуры деления. Вместо нее используют обращение матриц.

$$
\textbf{X}^{-1}\textbf{X} = \textbf{I}
$$
Произведение инверсии матрицы и исходной матрицы дает единичную матрицу


##Обращение (инверсия) матриц 
Только квадратные матрицы, имеющие определитель неравный нулю, могут иметь обратную матрицу. 

Поэтому для квадратных матриц  справедливо $\textbf{X} \textbf{X}^{-1} = \textbf{X}^{-1} \textbf{X}$

##Решение в среде R
Создадим матрицу
```{r, echo=FALSE}
X <- matrix(c(seq(1, 8),10), nrow = 3, byrow = T)
X
```

Ее определитель
```{r}
det(X)
```

##Решение в среде R
Обратная матрица 
```{r}
solve(X)

```

По определению, $\textbf{X}^{-1}\textbf{X} = \textbf{I}$
```{r}
round(solve(X) %*% X )
```


#Примнение обращенных матриц 

##Решение систем линейных уравнений

Простейший случай использования обратных матриц - решение систем линейных уравнений
$$
\begin{cases}
1x + 2y + 3z = 2\\  
4x + 5y + 6z = 4 \\  
7x + 8y + 10z = 10   
\end{cases}
$$

Эту систему можно представить в матричном виде

$$
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 10
\end{pmatrix}
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
=
\begin{pmatrix}
2 \\ 4 \\ 10
\end{pmatrix}
$$

Тогда 

$$
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
=
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 10
\end{pmatrix}
^{-1}
\begin{pmatrix}
2 \\ 4 \\ 10
\end{pmatrix}
$$

##Задание 
Решите приведенную систему уравнений с использованием матричной алгебры 

$$
\begin{cases}
1x + 2y + 3z = 2\\  
4x + 5y + 6z = 4 \\  
7x + 8y + 10z = 10   
\end{cases}
$$



##Решение

```{r}
Coef <- matrix(c(1 , 2 , 3 ,
         4 , 5 , 6 ,
         7 , 8 , 10), byrow = T, ncol = 3)
Val <- c(2,4,10)

solve(Coef) %*% Val

```




#Подбор параметров линейной регрессии методом наименьших квадратов с использованием матричной алгебры

##Линейная регрессия в матричном виде

При подборе коэффициентов методом наименьших квадратов нам надо решить следующее матричное уравнение:
$$
\textbf{y} =  \textbf{X} \pmb{\beta}
$$


Здесь  

$\textbf{y}$ - вектор предсказанных значений      

$\textbf{X}$ - модельная матрица  $\begin{pmatrix} 1 & x_1  \\ 1 & x_2 \\ \vdots & \vdots \\ 1 & x_n \end{pmatrix}$   

$\pmb{\beta}$  - вектор коэффициентов модели





##Решение этого уравнения   

Умножим обе части уравнения на транспонированную матрицу $\textbf{X}'$  

$$ \textbf{X}'  \textbf{y} = \textbf{X}'\textbf{X} \pmb{\beta}$$

Матрица $\textbf{X}'\textbf{X}$ - это всегда квадратная матрица. Ее можно обратить.

Тогда
$$
\pmb{\beta} = [\textbf{X}'\textbf{X}]^{-1}[\textbf{X}'\textbf{y}]
$$


##Подбираем коэффициенты с помощью фунции `lm()`
```{r}
data(cars)
Mod <- lm(dist ~ speed, data = cars)
coefficients(Mod)
```

##Графическое отражение, построенное с помощью `geom_smooth()`
```{r}
library(ggplot2)
theme_set(theme_bw())
ggplot(cars, aes(x = speed, y = dist)) + geom_point() + geom_smooth(method = "lm")

```



##Вычисление коэффициентов линейной регрессии вручную

Находим вектор коэффициентов на основе уравнения $\pmb{\beta} = [\textbf{X}'\textbf{X}]^{-1}[\textbf{X}'\textbf{y}]$

```{r}
X <- model.matrix(~speed, data = cars)
Y <- cars$dist
betas <- solve(t(X) %*% X) %*% (t(X) %*% Y)
betas

```


##Вычисление вариационно-ковариационной матрицы 
Подобранные параметры - это лишь _оценки_ некоторых параметров, описывающих связь между зависимой переменной и предиктором в популяции.    

Варьирование параметров описывает *вриацонно-ковариационная матрица*.    

В среде `R`, если модель задана, например, с помощью функции `lm()`, эта матрица вычисляется так   
```{r}
vcov(Mod)
```



##Вычисление вариационо-ковариационной матрицы вручную

$$
\textbf{V}(\pmb{\beta}) = s^2[\textbf{X}'\textbf{X}]^{-1}
$$
где

$$
s^2 = \frac{\sum\limits_{\substack{i=1}}^n e_i^2}{n-k}
$$

$\sum\limits_{\substack{i=1}}^n e_i^2$ - сумма квадратов остатков   
$n$ - объем выборки   
$k$ - число параметров в модели

##Вычисление вариационо-ковариационной матрицы вручную
Вычисляем $\sum\limits_{\substack{i=1}}^n e_i^2$   

```{r}
predict_values <- X %*% betas

resid_values <- cars$dist - predict_values

s2 <- sum(resid_values^2)/(length(resid_values) - length(betas))

s2
```

##Вычисление вариационо-ковариационной матрицы вручную
Вычисляем вариационно-ковариационную матрицу

$$
\textbf{V}(\pmb{\beta}) = s^2[\textbf{X}'\textbf{X}]^{-1}
$$

```{r}
covbetas <- s2 * solve(t(X) %*% X)
covbetas
```


##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 1. Формируем искусственный датасет со всеми возможными значениями предиктора

```{r}
MyData <- data.frame(speed = seq(min(cars$speed), max(cars$speed)))
head(MyData)
```

##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 2. Формируем модельную матрицу для искусственно созданных данных

```{r}
X <- model.matrix( ~ speed, data = MyData)
head(X)

```

##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 3. Вычисляем предсказанные значения для искусственно созданных данных
```{r}
MyData$predicted <- X %*% betas
```


##Применение матричной алгебры для построения графиков регрессионных моделей 

Шаг 5. Вычисляем границы доверительных интервалов

```{r}
# Вычисляем стандартные отшибки путем перемножения матриц
  MyData$se <- sqrt(diag(X %*% covbetas %*% t(X)))

# Вычисляем доверительные интервалы
MyData$CiUp  <- MyData$predicted + 1.96 *MyData$se

MyData$CiLow  <- MyData$predicted - 1.96 *MyData$se

```

##Применение матричной алгебры для построения графиков регрессионных моделей  {.smaller .columns-2} 

Шаг 6. Строим график

```{r gg-manual, fig.height=5, fig.width=4, echo=FALSE}
ggplot(MyData, aes(x = speed, y = predicted)) + 
  geom_line(aes(x = speed, y = CiUp), 
            linetype = 2, size = 1) + 
  geom_line(aes(x = speed, y = CiLow), 
            linetype = 2, size = 1)+ 
  geom_abline(slope = betas[2], intercept = betas[1], 
              color = "blue", size=2) +
  geom_point(data = cars, aes(x = speed, y = dist)) +
  ylab("dist")
```
```{r gg-manual, fig.height=5, fig.width=4, eval=FALSE}
```



##Сравним результаты 


```{r, echo=FALSE, fig.height=6}
library(gridExtra)
Pl_gg <- ggplot(cars, aes(x = speed, y = dist)) + geom_point() + geom_smooth(method = "lm") 
Pl_hand <-ggplot(MyData, aes(x = speed, y = predicted)) +   geom_line(aes(x = speed, y = CiUp), linetype = 2, size = 0.5) + geom_line(aes(x = speed, y = CiLow), linetype = 2, size = 0.5) + geom_abline(slope = betas[2], intercept = betas[1], color = "blue", size=1) + geom_point(data = cars, aes(x = speed, y = dist)) + ylab("dist")

grid.arrange(Pl_gg, Pl_hand, ncol = 2)

```


# Not The End
![](images/matrix2.jpg)

##Что почитать
* Legendre P., Legendre L. (2012) Numerical ecology. Second english edition. Elsevier, Amsterdam. Глава 2. Matrix algebra: a summary.



